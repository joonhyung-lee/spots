{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "davinci\n",
      "gpt-4\n",
      "gpt-3.5-turbo-16k-0613\n",
      "text-davinci-001\n",
      "text-search-curie-query-001\n",
      "gpt-3.5-turbo\n",
      "babbage\n",
      "text-babbage-001\n",
      "gpt-4-0613\n",
      "gpt-3.5-turbo-16k\n",
      "curie-instruct-beta\n",
      "davinci-similarity\n",
      "code-davinci-edit-001\n",
      "text-similarity-curie-001\n",
      "ada-code-search-text\n",
      "gpt-3.5-turbo-0613\n",
      "text-search-ada-query-001\n",
      "babbage-search-query\n",
      "ada-similarity\n",
      "text-curie-001\n",
      "text-search-ada-doc-001\n",
      "text-search-babbage-query-001\n",
      "code-search-ada-code-001\n",
      "curie-search-document\n",
      "davinci-002\n",
      "text-search-davinci-query-001\n",
      "text-search-curie-doc-001\n",
      "babbage-search-document\n",
      "babbage-002\n",
      "babbage-code-search-text\n",
      "text-embedding-ada-002\n",
      "davinci-instruct-beta\n",
      "davinci-search-query\n",
      "text-similarity-babbage-001\n",
      "text-davinci-002\n",
      "code-search-babbage-text-001\n",
      "text-davinci-003\n",
      "text-search-davinci-doc-001\n",
      "code-search-ada-text-001\n",
      "gpt-4-0314\n",
      "ada-search-query\n",
      "text-similarity-ada-001\n",
      "ada-code-search-code\n",
      "whisper-1\n",
      "text-davinci-edit-001\n",
      "davinci-search-document\n",
      "curie-search-query\n",
      "babbage-similarity\n",
      "ada\n",
      "ada-search-document\n",
      "text-ada-001\n",
      "text-similarity-davinci-001\n",
      "curie-similarity\n",
      "babbage-code-search-code\n",
      "code-search-babbage-code-001\n",
      "text-search-babbage-doc-001\n",
      "gpt-3.5-turbo-0301\n",
      "curie\n",
      "curie:ft-korea-university-2023-04-02-06-34-56\n",
      "ft:gpt-3.5-turbo-0613:korea-university::7trkYzgO\n",
      "ft:gpt-3.5-turbo-0613:korea-university::7trKamW3\n",
      "ft:gpt-3.5-turbo-0613:korea-university::7tqbNGH5\n",
      "ft:gpt-3.5-turbo-0613:korea-university::7ttF0Dx2\n",
      "ft:gpt-3.5-turbo-0613:korea-university::7tqEGsAP\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import openai \n",
    "import os \n",
    "\n",
    "models = openai.Model.list()\n",
    "for model in models['data']:\n",
    "    print(model['id'])\n",
    "print(\"Done.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [text-davinci-003]: Text completion model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:  \n",
      "\n",
      "Mini and Pimo is a technology startup that develops an automated home assistant. It uses a combination of artificial intelligence and image recognition to help users manage their home. It can be used to automate tasks such as controlling lights and appliances, scheduling reminders, and monitoring home security. The system can also be used to track energy usage and suggest energy efficiency tips. The company was founded in 2019 and is based in Los Angeles, California.\n",
      "Answer:  \n",
      "\n",
      "Mini and Pimo is a technology startup that develops an automated home assistant. It uses a combination of artificial intelligence and image recognition to help users manage their home. It can be used to automate tasks such as controlling lights and appliances, scheduling reminders, and monitoring home security. The system can also be used to track energy usage and suggest energy efficiency tips. The company was founded in 2019 and is based in Los Angeles, California.\n"
     ]
    }
   ],
   "source": [
    "engine = \"text-davinci-003\"\n",
    "prompt = \"Give me details about the technology startup called Mini and Pimo\"\n",
    "response = openai.Completion.create(engine='text-davinci-003',\n",
    "                                   prompt=prompt,\n",
    "                                   max_tokens = 256,\n",
    "                                   temperature =0.7)\n",
    "print(\"Answer: \", response[\"choices\"][0]['text'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Q1. How many colonies were there in the original Thirteen Colonies?\n",
      "A. 4\n",
      "B. 6\n",
      "C. 8\n",
      "D. 13\n",
      "Correct Answer: D. 13\n",
      "Source: https://en.wikipedia.org/wiki/Thirteen_Colonies\n",
      "\n",
      "Q2. Who was the first President of the United States?\n",
      "A. George Washington\n",
      "B. Thomas Jefferson\n",
      "C. John Adams\n",
      "D. James Madison\n",
      "Correct Answer: A. George Washington\n",
      "Source: https://en.wikipedia.org/wiki/List_of_Presidents_of_the_United_States\n",
      "\n",
      "Q3. What was the result of the Battle of Gettysburg during the American Civil War?\n",
      "A. Confederate Victory\n",
      "B. Union Victory\n",
      "C. Draw\n",
      "D. No result\n",
      "Correct Answer: B. Union Victory\n",
      "Source: https://en.wikipedia.org/wiki/Battle_of_Gettysburg\n",
      "\n",
      "Q4. Under which amendment to the US Constitution did women gain the right to vote?\n",
      "A. 13th Amendment\n",
      "B. 15th Amendment\n",
      "C. 17th Amendment\n",
      "D. 19th Amendment\n",
      "Correct Answer: D. 19th Amendment\n",
      "Source: https://en.\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Toy-example \"\"\"\n",
    "def create_test_prompt(topic, num_questions, num_possible_answers):\n",
    "    prompt = f\"Create a multiple choice quiz on the topic of {topic} consisting {num_questions}\"\\\n",
    "    +f\"Each question should have {num_possible_answers} options.\"\\\n",
    "    +f\"Also include the correct answer for each question using the starting string 'Correct Answer:' try to add sources with wikipedia link to support your answer and ask only objective questions\"\n",
    "    return prompt\n",
    "\n",
    "def create_student_view(test,num_questions):\n",
    "    student_view = {1:\"\"}\n",
    "    question_number =1 \n",
    "    for line in test.split(\"\\n\"):\n",
    "        if not line.startswith(\"Correct Answer:\"):\n",
    "            student_view[question_number] += line+'\\n'\n",
    "        else:\n",
    "            if question_number < num_questions:\n",
    "                question_number +=1\n",
    "                student_view[question_number]= ''\n",
    "    return student_view\n",
    "\n",
    "def extract_answer(test,num_questions):\n",
    "    answers = {1:\"\"}\n",
    "    question_number =1 \n",
    "    for line in test.split(\"\\n\"):\n",
    "        if line.startswith(\"Correct Answer:\"):\n",
    "            answers[question_number] += line+'\\n'\n",
    "            if question_number < num_questions:\n",
    "                question_number +=1\n",
    "                answers[question_number]= ''\n",
    "    return answers\n",
    "\n",
    "def take(student_view):\n",
    "    student_answers = {}\n",
    "    for question, question_view in student_view.items():\n",
    "        print(question_view)\n",
    "        answer = input(\"Enter your answer: \")\n",
    "        student_answers[question] = answer\n",
    "    return student_answers\n",
    "\n",
    "response =openai.Completion.create(engine = 'text-davinci-003',\n",
    "                                  prompt=create_test_prompt(\"US History\",4,4),\n",
    "                                  max_tokens =256,\n",
    "                                  temperature = 0.7)\n",
    "\n",
    "print(response['choices'][0]['text'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Q1. How many colonies were there in the original Thirteen Colonies?\n",
      "A. 4\n",
      "B. 6\n",
      "C. 8\n",
      "D. 13\n",
      "\n",
      "Source: https://en.wikipedia.org/wiki/Thirteen_Colonies\n",
      "\n",
      "Q2. Who was the first President of the United States?\n",
      "A. George Washington\n",
      "B. Thomas Jefferson\n",
      "C. John Adams\n",
      "D. James Madison\n",
      "\n",
      "Source: https://en.wikipedia.org/wiki/List_of_Presidents_of_the_United_States\n",
      "\n",
      "Q3. What was the result of the Battle of Gettysburg during the American Civil War?\n",
      "A. Confederate Victory\n",
      "B. Union Victory\n",
      "C. Draw\n",
      "D. No result\n",
      "\n",
      "Source: https://en.wikipedia.org/wiki/Battle_of_Gettysburg\n",
      "\n",
      "Q4. Under which amendment to the US Constitution did women gain the right to vote?\n",
      "A. 13th Amendment\n",
      "B. 15th Amendment\n",
      "C. 17th Amendment\n",
      "D. 19th Amendment\n",
      "Source: https://en.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: 'Correct Answer: D. 13\\n',\n",
       " 2: 'Correct Answer: A. George Washington\\n',\n",
       " 3: 'Correct Answer: B. Union Victory\\n',\n",
       " 4: 'Correct Answer: D. 19th Amendment\\n'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = create_student_view(response['choices'][0]['text'],4)\n",
    "for key in result:\n",
    "    print(result[key])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "extract_answer(response['choices'][0]['text'],4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# student_view = create_student_view(response['choices'][0]['text'],4)\n",
    "# answers = extract_answer(response['choices'][0]['text'],4)\n",
    "# student_answers = take(student_view)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [gpt-3.5-turbo]: ChatGPT 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatGPT API reply: The 2014 World Cup was held in Brazil.\n"
     ]
    }
   ],
   "source": [
    "model_engine='gpt-3.5-turbo'\n",
    "input_text = \"Where is the 2014 World Cup held?\"\n",
    "response = openai.ChatCompletion.create(\n",
    "   model=model_engine,\n",
    "   messages=[{\"role\": \"user\", \"content\": input_text }]\n",
    ")\n",
    "output_text = response['choices'][0]['message']['content']\n",
    "print(\"ChatGPT API reply:\", output_text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [gpt-4]: ChatGPT 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatGPT API reply: The 2014 World Cup was held in Brazil.\n"
     ]
    }
   ],
   "source": [
    "model_engine='gpt-4'\n",
    "input_text = \"Where is the 2014 World Cup held?\"\n",
    "response = openai.ChatCompletion.create(\n",
    "   model=model_engine,\n",
    "   messages=[{\"role\": \"user\", \"content\": input_text }]\n",
    ")\n",
    "output_text = response['choices'][0]['message']['content']\n",
    "print(\"ChatGPT API reply:\", output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

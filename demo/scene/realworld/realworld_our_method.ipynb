{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing Mujoco env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuJoCo version:[2.3.7]\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import mujoco\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append(\"../../../\")\n",
    "from utils.mujoco_parser import MuJoCoParserClass\n",
    "from utils.util import sample_xyzs,rpy2r,r2quat\n",
    "np.set_printoptions(precision=2,suppress=True,linewidth=100)\n",
    "plt.rc('xtick',labelsize=6); plt.rc('ytick',labelsize=6)\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "print (\"MuJoCo version:[%s]\"%(mujoco.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window\n"
     ]
    }
   ],
   "source": [
    "xml_path = '../../../asset/scene_realworld_wo_shelf.xml'\n",
    "env = MuJoCoParserClass(name='Place task scene: Office table',rel_xml_path=xml_path,VERBOSE=False, MODE='window')\n",
    "print(env.MODE)\n",
    "\n",
    "# Move tables and robot base\n",
    "env.model.body('base_table').pos = np.array([0,0,0])\n",
    "env.model.body('avoiding_object_table').pos = np.array([0.38+0.45,0,0])\n",
    "env.model.body('base').pos = np.array([-0.18,0,0.79])\n",
    "env.model.body('right_object_table').pos = np.array([-0.05,-0.80,0])\n",
    "env.model.body('left_object_table').pos = np.array([-0.05,0.80,0])\n",
    "\n",
    "# Place objects\n",
    "tray_pos = np.array([ 0.9, 0.0, 0.8])\n",
    "bowl_red_pos = np.array([ 0.9, 0.3, 0.8])\n",
    "bowl_blue_pos = np.array([ 0.9, -0.3, 0.8])\n",
    "env.model.joint(env.model.body('tray_gray').jntadr[0]).qpos0[:3] = tray_pos\n",
    "env.model.joint(env.model.body('kitchen-bowl-red').jntadr[0]).qpos0[:3] = bowl_red_pos\n",
    "env.model.joint(env.model.body('kitchen-bowl-blue').jntadr[0]).qpos0[:3] = bowl_blue_pos\n",
    "\n",
    "env.model.joint(env.model.body('ycb-apple-2').jntadr[0]).qpos0[:3] = bowl_red_pos + np.array([0.0,0.0,0.02])\n",
    "env.model.joint(env.model.body('ycb-banana-2').jntadr[0]).qpos0[:3] = tray_pos + np.array([0.0,0.03,0.2])\n",
    "env.model.joint(env.model.body('ycb-banana-2').jntadr[0]).qpos0[3:] = r2quat(rpy2r(np.radians([0, 0, 90])))\n",
    "env.model.joint(env.model.body('ycb-lemon-2').jntadr[0]).qpos0[:3] = tray_pos + np.array([-0.03,-0.07,0.02])\n",
    "env.model.joint(env.model.body('ycb-orange-2').jntadr[0]).qpos0[:3] = bowl_blue_pos + np.array([0.0,0.0,0.02])\n",
    "\n",
    "# Target objects\n",
    "env.model.joint(env.model.body('ycb-apple').jntadr[0]).qpos0[:3] = np.array([0.1, -0.6, 0.8])\n",
    "env.model.joint(env.model.body('ycb-banana').jntadr[0]).qpos0[:3] = np.array([-5.0,-1.5,0.2])\n",
    "env.model.joint(env.model.body('ycb-lemon').jntadr[0]).qpos0[:3] = np.array([0.0, -0.6, 0.8])\n",
    "env.model.joint(env.model.body('ycb-orange').jntadr[0]).qpos0[:3] = np.array([-0.1, -0.6, 0.8])\n",
    "\n",
    "joint_names = env.rev_joint_names[:6]\n",
    "idxs_forward = [env.model.joint(joint_name).qposadr[0] for joint_name in env.joint_names[:6]]\n",
    "idxs_jacobian = [env.model.joint(joint_name).dofadr[0] for joint_name in env.joint_names[:6]]\n",
    "list1, list2 = env.ctrl_joint_idxs, idxs_forward\n",
    "idxs_step = []\n",
    "for i in range(len(list2)):\n",
    "    if list2[i] in list1:\n",
    "        idxs_step.append(list1.index(list2[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.open_interactive_viewer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.  , -0.  ,  0.  ,  0.04,  0.04,  0.04])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.model.geom_aabb[env.model.body('ycb-orange').geomadr][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tray_gray': {'position': array([0.9, 0. , 0.8]), 'size': array([0.17, 0.07, 0.28])}, 'kitchen-bowl-blue': {'position': array([ 0.9, -0.3,  0.8]), 'size': array([0.08, 0.08, 0.03])}, 'kitchen-bowl-red': {'position': array([0.9, 0.3, 0.8]), 'size': array([0.08, 0.08, 0.03])}, 'ycb-apple-2': {'position': array([0.9 , 0.3 , 0.82]), 'size': array([0.03, 0.03, 0.03])}, 'ycb-banana-2': {'position': array([0.9 , 0.03, 1.  ]), 'size': array([0.02, 0.04, 0.01])}, 'ycb-lemon-2': {'position': array([ 0.87, -0.07,  0.82]), 'size': array([0.03, 0.03, 0.03])}, 'ycb-orange-2': {'position': array([ 0.9 , -0.3 ,  0.82]), 'size': array([0.04, 0.04, 0.04])}}\n",
      "['tray_gray', 'kitchen-bowl-blue', 'kitchen-bowl-red', 'ycb-apple-2', 'ycb-banana-2', 'ycb-lemon-2', 'ycb-orange-2']\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "\n",
    "# object position lists on the table\n",
    "obj_pos_list_table = {}\n",
    "obj_pos_list_table['tray_gray'] = {'position':env.get_p_body('tray_gray'), 'size':np.array([0.17,0.07,0.28])}\n",
    "obj_pos_list_table['kitchen-bowl-blue'] = {'position':env.get_p_body('kitchen-bowl-blue'), 'size': np.array([0.08,0.08,0.03])}\n",
    "obj_pos_list_table['kitchen-bowl-red'] = {'position':env.get_p_body('kitchen-bowl-red'), 'size': np.array([0.08,0.08,0.03])}\n",
    "\n",
    "obj_pos_list_table['ycb-apple-2'] = {'position':env.get_p_body('ycb-apple-2'), 'size': np.array([0.03,0.03,0.03])}\n",
    "obj_pos_list_table['ycb-banana-2'] = {'position':env.get_p_body('ycb-banana-2'), 'size': np.array([0.02,0.04,0.01])}\n",
    "obj_pos_list_table['ycb-lemon-2'] = {'position':env.get_p_body('ycb-lemon-2'), 'size': np.array([0.03,0.03,0.03])}\n",
    "obj_pos_list_table['ycb-orange-2'] = {'position':env.get_p_body('ycb-orange-2'), 'size': np.array([0.04,0.04,0.04])}\n",
    "\n",
    "print(obj_pos_list_table)\n",
    "print(list(obj_pos_list_table.keys()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get feasible_score_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/without_shelf/feasible_pcd.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m nbins \u001b[39m=\u001b[39m \u001b[39m50\u001b[39m\n\u001b[1;32m      6\u001b[0m n_samples \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n\u001b[0;32m----> 8\u001b[0m feasible_pcds \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mload(\u001b[39m'\u001b[39;49m\u001b[39m./data/without_shelf/feasible_pcd.npy\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      9\u001b[0m \u001b[39m# feasible_pcds = np.load('./data_score/workspace_white_rack_dense.npy')\u001b[39;00m\n\u001b[1;32m     10\u001b[0m score_map, di \u001b[39m=\u001b[39m get_score_map(feasible_pcds, nbins\u001b[39m=\u001b[39mnbins, bandwidth\u001b[39m=\u001b[39mbandwidth, PLOT\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.13/envs/llm/lib/python3.8/site-packages/numpy/lib/npyio.py:405\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    403\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 405\u001b[0m     fid \u001b[39m=\u001b[39m stack\u001b[39m.\u001b[39menter_context(\u001b[39mopen\u001b[39;49m(os_fspath(file), \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[1;32m    406\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    408\u001b[0m \u001b[39m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/without_shelf/feasible_pcd.npy'"
     ]
    }
   ],
   "source": [
    "sys.path.append('../../../utils/')\n",
    "from score_map import get_score_map, sample_pcd_from_score_map, plot_score_map\n",
    "\n",
    "bandwidth = 0.01\n",
    "nbins = 50\n",
    "n_samples = 10\n",
    "\n",
    "feasible_pcds = np.load('./data/without_shelf/feasible_pcd.npy')\n",
    "score_map, di = get_score_map(feasible_pcds, nbins=nbins, bandwidth=bandwidth, PLOT=True)\n",
    "sampled_physical = sample_pcd_from_score_map(score_map, feasible_pcds, di, nbins=nbins, num_samples=n_samples)\n",
    "plot_score_map(score_map, feasible_pcds, nbins=nbins)\n",
    "\n",
    "# Plotting\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "x, y, z = feasible_pcds[:, 0], feasible_pcds[:, 1], feasible_pcds[:, 2]\n",
    "\n",
    "# Hide grid lines\n",
    "# ax.grid(False)\n",
    "\n",
    "ax.view_init(azim=0, elev=90)\n",
    "# ax.set_xticks([])\n",
    "# ax.set_yticks([])\n",
    "# ax.set_zticks([])\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "ax.set_zlabel('Z')\n",
    "ax.scatter(x, y, z, c='r', marker='o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interact with GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openai version:[0.27.8]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "import sys\n",
    "sys.path.append('../../../')\n",
    "from utils.gpt_helper import set_openai_api_key_from_txt,GPTchatClass,printmd\n",
    "from utils.wiki_helper import wiki_search\n",
    "from utils.util import printmd,extract_quoted_words\n",
    "print (\"openai version:[%s]\"%(openai.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key Ready from [../../../key/my_key.txt].\n",
      "Chat agent using [gpt-4] initialized with the follow role:[Your are a helpful assistant summarizing infromation and answering user queries.]\n"
     ]
    }
   ],
   "source": [
    "# set_openai_api_key_from_txt(key_path='../../../key/rilab_key.txt')\n",
    "set_openai_api_key_from_txt(key_path='../../../key/my_key.txt')\n",
    "GPT = GPTchatClass(\n",
    "    gpt_model='gpt-4', # 'gpt-3.5-turbo' / 'gpt-4'\n",
    "    role_msg='Your are a helpful assistant summarizing infromation and answering user queries.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_description_list = [\"plate\", \"book\", \"apple\", \"pockey\"]\n",
    "target_object_name = \"plate\"\n",
    "\n",
    "user_msg = \\\n",
    "    f\"\"\"\n",
    "    I will give you some scene descriptions, task descriptions and the user's preferred trajectory information:\n",
    "\n",
    "    Scene description:\n",
    "    There are objects of {list(obj_pos_list_table.keys())} on the table. Their respective positions and sizes are shown below.\n",
    "    - {obj_pos_list_table}\n",
    "    The table is located at [0.98,0,0.79], and the areas where objects can be placed on the table are shown below.\n",
    "    - x: [0.65, 1.2]\n",
    "    - y: [-0.38, 0.38]\n",
    "    - z: [0.8, 0.9]\n",
    "\n",
    "    Task description: \n",
    "    The task is to place the {target_object_name} on the front table.\n",
    "\n",
    "    [Rules]\n",
    "\t1. The environment contains {list(obj_pos_list_table.keys())}. Do not invent new objects not listed here.\n",
    "\t2. The terminate condition is either when the manipulator has successfully placed the intended object into the bookshelf, ensuring it is stably settled, or if a critical failure occurs, such as knocking over a wine glass, dropping an object during transfer, or damaging an object or the bookshelf.\n",
    "\t3. You can assume that the robot can do anything, even for the most challenging task.\n",
    "\t4. Your plan should be as close to the provided template as possible. You can add additional information if you think it is necessary.\n",
    "\t5. Once you've gotten as much information as you think you need to perform the task, you can do it without asking any more questions, and you NEED to say, 'I get it.'. You should describe your plan in detail.\n",
    "    6. You can say the region(area) where the object can be placed on the table. You should follow this format: [Object_Name], Spatial_Relationship_to_the_Object, use ONLY the list of objects I provided.\n",
    "    7. The clusters of the regions are just for reference. But the categories of the regions are not fixed. You can change the categories of the regions if you think it is necessary.\n",
    "\t\n",
    "    This is an example of instruction. For example, answer the output following instructions.\n",
    "    For example, the answer can be like this:\n",
    "\n",
    "    User: Based on the information I have provided, please recommend a suitable area to place {target_object_name} to accomplish the task successfully, and also let me know which region(area) is unsuitable to place it for the same purpose. Only you can say the region.\n",
    "    GPT-4: Certainly! I have analyzed the provided positions and clustered them into five groups based on their spatial relationships and proximity to other objects in the table. \n",
    "    Here are the clusters:\n",
    "    I recommend the region [red_bowl] to place the {target_object_name}. This area provides a balance between accessibility and stability, without interfering with other objects on the table. It's also aesthetically pleasing as it maintains symmetry on the table.\n",
    "    And I recommend not to place the {target_object_name} in the region [blue_bowl]. This area is too close to the mug cup, which may cause the {target_object_name} to fall down when the robot is trying to place it.\n",
    "    Summary: Recommended region: [red_bowl], Not recommended region: [blue_bowl]\n",
    "\n",
    "    If you understand, Say \"I understand\" and I will start the simulation.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[USER_MSG]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "    I will give you some scene descriptions, task descriptions and the user's preferred trajectory information:\n",
       "\n",
       "    Scene description:\n",
       "    There are objects of ['kitchen-drainer', 'tray', 'mug_cup', 'kitchen-plate-2', 'kitchen-plate-3'] on the table. Their respective positions and sizes are shown below.\n",
       "    - {'kitchen-drainer': {'position': array([0.9 , 0.35, 0.82]), 'size': array([0.17, 0.07, 0.28])}, 'tray': {'position': array([ 0.9, -0.3,  0.8]), 'size': array([0.11, 0.15, 0.01])}, 'mug_cup': {'position': array([ 0.9 , -0.3 ,  0.85]), 'size': array([0.05, 0.07, 0.1 ])}, 'kitchen-plate-2': {'position': array([0.9 , 0.29, 1.07]), 'size': array([0.1 , 0.1 , 0.01])}, 'kitchen-plate-3': {'position': array([0.9 , 0.23, 1.07]), 'size': array([0.1 , 0.1 , 0.01])}}\n",
       "    The table is located at [0.98,0,0.79], and the areas where objects can be placed on the table are shown below.\n",
       "    - x: [0.65, 1.2]\n",
       "    - y: [-0.38, 0.38]\n",
       "    - z: [0.8, 0.9]\n",
       "\n",
       "    Task description: \n",
       "    The task is to place the plate on the front table.\n",
       "\n",
       "    [Rules]\n",
       "\t1. The environment contains ['kitchen-drainer', 'tray', 'mug_cup', 'kitchen-plate-2', 'kitchen-plate-3']. Do not invent new objects not listed here.\n",
       "\t2. The terminate condition is either when the manipulator has successfully placed the intended object into the bookshelf, ensuring it is stably settled, or if a critical failure occurs, such as knocking over a wine glass, dropping an object during transfer, or damaging an object or the bookshelf.\n",
       "\t3. You can assume that the robot can do anything, even for the most challenging task.\n",
       "\t4. Your plan should be as close to the provided template as possible. You can add additional information if you think it is necessary.\n",
       "\t5. Once you've gotten as much information as you think you need to perform the task, you can do it without asking any more questions, and you NEED to say, 'I get it.'. You should describe your plan in detail.\n",
       "    6. You can say the region(area) where the object can be placed on the table. You should follow this format: [Object_Name], Spatial_Relationship_to_the_Object, use ONLY the list of objects I provided.\n",
       "    7. The clusters of the regions are just for reference. But the categories of the regions are not fixed. You can change the categories of the regions if you think it is necessary.\n",
       "\t\n",
       "    This is an example of instruction. For example, answer the output following instructions.\n",
       "    For example, the answer can be like this:\n",
       "\n",
       "    User: Based on the information I have provided, please recommend a suitable area to place plate to accomplish the task successfully, and also let me know which region(area) is unsuitable to place it for the same purpose. Only you can say the region.\n",
       "    GPT-4: Certainly! I have analyzed the provided positions and clustered them into five groups based on their spatial relationships and proximity to other objects in the table. \n",
       "    Here are the clusters:\n",
       "    I recommend the region [Dish_Rack] to place the plate. This area provides a balance between accessibility and stability, without interfering with other objects on the table. It's also aesthetically pleasing as it maintains symmetry on the table.\n",
       "    And I recommend not to place the plate in the region [Mug_Cup]. This area is too close to the mug cup, which may cause the plate to fall down when the robot is trying to place it.\n",
       "    Summary: Recommended region: [Dish_Rack], Not recommended region: [Mug_Cup]\n",
       "\n",
       "    If you understand, Say \"I understand\" and I will start the simulation.\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GPT_OUTPUT]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Based on the information given, here are my area recommendations and decisions for the placing of the plate:\n",
       "\n",
       "Recommended Area:\n",
       "After analyzing the placements of all objects and their positions and sizes, I would recommend placing the plate in the 'kitchen-drainer' region as it has enough space and it's in a stable location. It also has an easy reach for the robot arm and wouldn't interfere with the other objects.\n",
       "\n",
       "Unsuitable Area:\n",
       "The 'mug_cup' region is unsuitable due to its close proximity to the mug cup which poses an increased risk of the plate falling over or colliding with the mug during placement. \n",
       "\n",
       "Summary: Recommended region: [kitchen-drainer], Not recommended region: [mug_cup]. \n",
       "\n",
       "Once you confirm the understanding of these instructions, I can begin with the simulation."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response_content = GPT.chat(\n",
    "    user_msg=user_msg,PRINT_USER_MSG=True,PRINT_GPT_OUTPUT=True,\n",
    "    RESET_CHAT=True,RETURN_RESPONSE=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('kitchen-drainer', 'mug_cup')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = response_content\n",
    "pattern_recommended = r'recommended region: \\[(.*?)\\]'\n",
    "pattern_not_recommended = r'not recommended region: \\[(.*?)\\]'\n",
    "\n",
    "# Use re.search to find the first occurrence of the patterns\n",
    "recommended_region = re.search(pattern_recommended, text.lower())\n",
    "not_recommended_region = re.search(pattern_not_recommended, text.lower())\n",
    "\n",
    "# Extract the matched groups\n",
    "recommended_region = recommended_region.group(1) if recommended_region else None\n",
    "not_recommended_region = not_recommended_region.group(1) if not_recommended_region else None\n",
    "\n",
    "recommended_region, not_recommended_region"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

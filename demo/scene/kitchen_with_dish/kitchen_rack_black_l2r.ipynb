{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semi-autonomous Teleoperation Demo : Place task in `Kitchen Plate` scene with `small size dish rack`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse `Realistic Scene`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuJoCo version:[2.3.3]\n"
     ]
    }
   ],
   "source": [
    "import mujoco#,cv2,pyvista\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append('../../../')\n",
    "from utils.mujoco_parser import MuJoCoParserClass\n",
    "\n",
    "from utils.util import sample_xyzs,rpy2r,r2rpy,r2quat,compute_view_params,get_interp_const_vel_traj, printmd\n",
    "np.set_printoptions(precision=2,suppress=True,linewidth=100)\n",
    "plt.rc('xtick',labelsize=6); plt.rc('ytick',labelsize=6)\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "print (\"MuJoCo version:[%s]\"%(mujoco.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window\n"
     ]
    }
   ],
   "source": [
    "xml_path = '../../../asset/scene_kitchen_dish_rack_black.xml'\n",
    "env = MuJoCoParserClass(name='Place task scene: Plate table',rel_xml_path=xml_path,VERBOSE=False, MODE='window')\n",
    "print(env.MODE)\n",
    "\n",
    "# Move tables and robot base\n",
    "env.model.body('base_table').pos = np.array([0,0,0])\n",
    "env.model.body('base').pos = np.array([0.18,0,0.79])\n",
    "env.model.body('avoiding_object_table').pos = np.array([0.38+0.45,0,0])\n",
    "env.model.body('right_object_table').pos = np.array([-0.05,-0.80,0])\n",
    "env.model.body('left_object_table').pos = np.array([-1.5,0.80,0])\n",
    "\n",
    "# Place objects\n",
    "obj_box_names = [body_name for body_name in env.body_names\n",
    "             if body_name is not None and (body_name.startswith(\"obj_box\"))]\n",
    "n_box_obj = len(obj_box_names)\n",
    "env.place_objects_random(n_obj=n_box_obj, obj_names=obj_box_names, x_range=[0.80, 1.15], y_range=[-3.15, -2.15], COLORS=False, VERBOSE=True)\n",
    "\n",
    "jntadr_mug_cup = env.model.body('mug_cup').jntadr[0]\n",
    "env.model.joint(jntadr_mug_cup).qpos0[:3] = np.array([ 0.9, -0.3, 0.85])\n",
    "env.model.joint(jntadr_mug_cup).qpos0[3:] = r2quat(rpy2r(np.radians([0, 0, np.random.rand() * 360])))\n",
    "\n",
    "jntadr_tray = env.model.body('tray').jntadr[0]\n",
    "env.model.joint(jntadr_tray).qpos0[:3] = np.array([0.9,-0.3,0.80])\n",
    "# env.model.joint(jntadr_tray).qpos0[3:] = r2quat(rpy2r(np.radians([0, 0, 0])))\n",
    "\n",
    "jntadr_dish_rack = env.model.body('kitchen-drainer').jntadr[0]\n",
    "pos_dish_rack = np.array([0.9,0.35,0.82])\n",
    "env.model.joint(jntadr_dish_rack).qpos0[:3] = pos_dish_rack\n",
    "dish_rack_random_rot = 0 # np.random.rand() * 360\n",
    "env.model.joint(jntadr_dish_rack).qpos0[3:] = r2quat(rpy2r(np.radians([0, 0, dish_rack_random_rot])))\n",
    "\n",
    "\n",
    "# Target dish\n",
    "env.model.joint(env.model.body('kitchen-plate').jntadr[0]).qpos0[:3] = np.array([0.2, -0.7, 0.8])\n",
    "# Set the dishes\n",
    "env.model.joint(env.model.body('kitchen-plate-2').jntadr[0]).qpos0[:3] = pos_dish_rack + np.array([0.,-0.06, 0.25])\n",
    "env.model.joint(env.model.body('kitchen-plate-2').jntadr[0]).qpos0[3:] = r2quat(rpy2r(np.radians([0, 90, 90])))\n",
    "env.model.joint(env.model.body('kitchen-plate-3').jntadr[0]).qpos0[:3] = pos_dish_rack + np.array([0., -0.12, 0.25])\n",
    "env.model.joint(env.model.body('kitchen-plate-3').jntadr[0]).qpos0[3:] = r2quat(rpy2r(np.radians([0, 90, 90])))\n",
    "env.model.joint(env.model.body('kitchen-plate-4').jntadr[0]).qpos0[:3] = pos_dish_rack + np.array([-3.5, 0., 0.25])\n",
    "env.model.joint(env.model.body('kitchen-plate-4').jntadr[0]).qpos0[3:] = r2quat(rpy2r(np.radians([0, 90, 90])))\n",
    "\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import openai \n",
    "import os \n",
    "openai.api_key = 'your key' \n",
    "\n",
    "def gauss_2d(mu, sigma=0.01):\n",
    "    x = random.gauss(mu[0], sigma)\n",
    "    y = random.gauss(mu[1], sigma)\n",
    "    return (x, y)\n",
    "\n",
    "\n",
    "class ChatGPT():\n",
    "    def __init__ (self, model_engine='text-davinci-003'):\n",
    "        self.model_engine = model_engine\n",
    "        self.msg_history_turbo = []\n",
    "        self.msg_history_davinci = \"\"\n",
    "        self.role = 'user'\n",
    "        \n",
    "    def get_answer(self, prompt=None):\n",
    "        if self.model_engine == 'gpt-3.5-turbo':\n",
    "            self.msg_history_turbo.append({\"role\": self.role, \"content\":prompt})\n",
    "            response   = openai.ChatCompletion.create(\n",
    "            model      = self.model_engine,\n",
    "            messages   = self.msg_history_turbo)\n",
    "            reply_text = response['choices'][0]['message']['content']\n",
    "            self.msg_history_turbo.append({\"role\":\"assistant\", \"content\":reply_text})\n",
    "\n",
    "        elif self.model_engine == 'text-davinci-003': \n",
    "            self.msg_history_davinci += \"You: \"+prompt \n",
    "            response   = openai.Completion.create(\n",
    "            engine     = self.model_engine,\n",
    "            prompt     = self.msg_history_davinci,\n",
    "            max_tokens = 512,\n",
    "            temperature= 1.0,\n",
    "            n          = 1,\n",
    "            #stop       = [\"You:\", \"AI:\"]\n",
    "            )\n",
    "            reply_text = response.choices[0].text.strip().replace('Answer: ', '')\n",
    "            self.msg_history_davinci+=\"\\n\"+\"AI: \"+reply_text+\"\\n\"\n",
    "        # print(\"ChatGPT: {}\".format(reply_text))\n",
    "        return reply_text\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:  Yes.\n",
      "Answer:  Yes.\n",
      "Answer:  ```\n",
      "import numpy as np\n",
      "\n",
      "reset_reward()\n",
      "set_l2_distance_reward(\"dish plate\", \"dish rack\")\n",
      "set_obj_position_reward(\"dish plate\", 0.16, 0, 0.18)\n",
      "set_obj_orientation_reward(\"dish plate\", np.deg2rad(0), np.deg2rad(0))\n",
      "\n",
      "execute_plan(2)\n",
      "```\n",
      "\n",
      "Answer:  Yes.\n",
      "Answer:  Yes.\n",
      "Answer:  Here is the corresponding reward specifying program to put a dish plate into a dish rack:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "\n",
      "reset_reward()\n",
      "set_l2_distance_reward(\"dish rack\", \"dish plate\")\n",
      "set_obj_orientation_reward(\"dish plate\", 0, 0)\n",
      "set_obj_position_reward(\"dish plate\", 0.03, -0.03, 0.09)\n",
      "\n",
      "execute_plan(2)\n",
      "```\n",
      "\n",
      "In this plan, we are setting the rewards to encourage the dish plate to be close to the dish rack, have a specific orientation (parallel to the ground), and be positioned at the desired coordinates relative to the dish rack. Afterwards, we execute the plan for 2 seconds.\n",
      "\n",
      "Please note that the position values provided for the dish plate are based on estimation and may require adjustment depending on the actual situation.\n",
      "Answer:  Yes.\n",
      "Answer:  Yes.\n",
      "Answer:  ```\n",
      "# Reset the reward to default values\n",
      "reset_reward()\n",
      "\n",
      "# Set the reward to minimize the distance between the dish rack and the dish plate\n",
      "set_l2_distance_reward(\"dish rack\", \"dish plate\")\n",
      "\n",
      "# Set the reward to orient the dish plate to a target rotation around the x-axis (pitch) and z-axis (yaw)\n",
      "set_obj_orientation_reward(\"dish plate\", np.deg2rad(0), np.deg2rad(0))\n",
      "\n",
      "# Set the reward to position the dish plate to a target offset from the dish rack's position\n",
      "set_obj_position_reward(\"dish plate\", 0.03, 0, 0)\n",
      "\n",
      "# Execute the plan for 2 seconds\n",
      "execute_plan(2)\n",
      "```\n",
      "Answer:  Yes.\n",
      "Answer:  Yes.\n",
      "Answer:  ```\n",
      "import numpy as np\n",
      "\n",
      "reset_reward()\n",
      "set_l2_distance_reward(\"dish rack\", \"dish plate\")\n",
      "set_obj_orientation_reward(\"dish plate\", 0, 0)\n",
      "set_obj_position_reward(\"dish plate\", 0, -0.06, 0.11)\n",
      "\n",
      "execute_plan(2)\n",
      "```\n",
      "\n",
      "Answer:  Yes.\n",
      "Answer:  Yes.\n",
      "Answer:  ```\n",
      "import numpy as np\n",
      "\n",
      "reset_reward()\n",
      "set_l2_distance_reward(\"dish rack\", \"dish plate\")\n",
      "set_obj_orientation_reward(\"dish plate\", 0, 0)\n",
      "set_obj_position_reward(\"dish plate\", 0.03, -0.06, 0.21)\n",
      "execute_plan(4)\n",
      "```\n",
      "\n",
      "Answer:  Yes.\n",
      "Answer:  Yes.\n",
      "Answer:  ```\n",
      "import numpy as np\n",
      "\n",
      "reset_reward()\n",
      "set_l2_distance_reward(\"dish plate\", \"dish rack\")\n",
      "set_obj_position_reward(\"dish plate\", 0.17, 0.07, 0.0)\n",
      "set_obj_orientation_reward(\"dish plate\", 0.0, 0.0)\n",
      "\n",
      "execute_plan(2)\n",
      "```\n",
      "Answer:  Yes.\n",
      "Answer:  Yes.\n",
      "Answer:  ```\n",
      "import numpy as np\n",
      "\n",
      "reset_reward()\n",
      "set_l2_distance_reward(\"dish rack\", \"dish plate\")\n",
      "set_obj_orientation_reward(\"dish plate\", 0, 0)\n",
      "set_obj_position_reward(\"dish plate\", 0, 0.04, 0.14)\n",
      "\n",
      "execute_plan(2)\n",
      "```\n",
      "\n",
      "Answer:  Yes.\n",
      "Answer:  Yes.\n",
      "Answer:  ```\n",
      "import numpy as np\n",
      "\n",
      "reset_reward()\n",
      "set_l2_distance_reward(\"dish rack\", \"dish plate\")\n",
      "set_obj_orientation_reward(\"dish plate\", np.deg2rad(0), 0)\n",
      "set_obj_position_reward(\"dish plate\", 0.03, 0, 0.28)\n",
      "\n",
      "execute_plan(2)\n",
      "```\n",
      "Answer:  Yes.\n",
      "Answer:  Yes.\n",
      "Answer:  ```\n",
      "import numpy as np\n",
      "\n",
      "reset_reward()\n",
      "set_l2_distance_reward(\"dish plate\", \"dish rack\")\n",
      "set_obj_orientation_reward(\"dish plate\", 0, 0)\n",
      "set_obj_position_reward(\"dish plate\", 0, 0, 0)\n",
      "\n",
      "execute_plan(2)\n",
      "```\n",
      "\n",
      "This code sets up the reward functions to encourage the dish plate to move closer to the dish rack, have its orientation aligned with the target, and be positioned at the target position. Then, the plan is executed for a duration of 2 seconds.\n",
      "Answer:  Yes.\n",
      "Answer:  Yes.\n",
      "Answer:  ```\n",
      "import numpy as np\n",
      "\n",
      "reset_reward()\n",
      "set_l2_distance_reward(\"dish plate\", \"dish rack\")\n",
      "\n",
      "# Move gripper close to dish plate\n",
      "set_obj_position_reward(\"dish plate\", 0, -0.02, 0)\n",
      "execute_plan()\n",
      "\n",
      "# Move dish plate close to dish rack\n",
      "set_obj_position_reward(\"dish plate\", 0.17, -0.02, 0)\n",
      "execute_plan()\n",
      "\n",
      "# Rotate dish plate\n",
      "set_obj_orientation_reward(\"dish plate\", np.deg2rad(0), np.deg2rad(0))\n",
      "execute_plan()\n",
      "\n",
      "# Move dish plate into dish rack\n",
      "set_obj_position_reward(\"dish plate\", 0.17, 0, 0)\n",
      "execute_plan()\n",
      "\n",
      "# Reset reward for next task\n",
      "reset_reward()\n",
      "```\n",
      "\n",
      "This code sets the appropriate rewards and executes the plan step by step to put the dish plate into the dish rack.\n",
      "Answer:  Yes, I understand.\n",
      "Answer:  Yes, I understand.\n",
      "Answer:  Here is the corresponding reward specifying program for placing a dish plate into a dish rack:\n",
      "\n",
      "```python\n",
      "import numpy as np\n",
      "\n",
      "reset_reward()\n",
      "set_l2_distance_reward(\"dish plate\", \"dish rack\")\n",
      "set_obj_orientation_reward(\"dish plate\", 0, 0)\n",
      "set_obj_position_reward(\"dish plate\", 0, -0.06, 0.94)\n",
      "\n",
      "execute_plan(2)\n",
      "```\n",
      "\n",
      "This program sets up the rewards to encourage the dish plate to be close to the dish rack, have a correct orientation, and to be positioned inside the rack. The `execute_plan` function then executes the plan for 2 seconds.\n",
      "\n",
      "Note: The values used for orientation and position are estimates and may need to be adjusted based on the actual setup of the robot and objects.\n",
      "\n",
      "If you have any other instructions or tasks, please let me know.\n",
      "Answer:  Yes.\n",
      "Answer:  Yes.\n",
      "Answer:  ```\n",
      "reset_reward()\n",
      "set_l2_distance_reward(\"dish plate\", \"dish rack\")\n",
      "set_obj_orientation_reward(\"dish plate\", 0, 0)\n",
      "set_obj_position_reward(\"dish plate\", 0, 0, 0.82)\n",
      "execute_plan(2)\n",
      "```\n",
      "Answer:  Yes.\n",
      "Answer:  Yes.\n",
      "Answer:  ```\n",
      "import numpy as np\n",
      "\n",
      "reset_reward()\n",
      "set_l2_distance_reward(\"dish rack\", \"dish plate\")\n",
      "set_obj_position_reward(\"dish plate\", 0, 0, 0.82)\n",
      "execute_plan(2)\n",
      "```\n",
      "\n",
      "Answer:  Yes.\n",
      "Answer:  Yes.\n",
      "Answer:  ```\n",
      "import numpy as np\n",
      "\n",
      "reset_reward()\n",
      "set_l2_distance_reward(\"dish rack\", \"dish plate\")\n",
      "set_obj_orientation_reward(\"dish plate\", np.deg2rad(0), 0)\n",
      "set_obj_position_reward(\"dish plate\", 0, -0.10, 0)\n",
      "\n",
      "execute_plan(2)\n",
      "```\n",
      "Answer:  Yes.\n",
      "Answer:  Yes.\n",
      "Answer:  ```\n",
      "import numpy as np\n",
      "\n",
      "reset_reward()\n",
      "set_l2_distance_reward(\"dish rack\", \"dish plate\")\n",
      "set_obj_orientation_reward(\"dish plate\", 0, 0)\n",
      "set_obj_position_reward(\"dish plate\", 0.03, -0.01, 0.29)\n",
      "\n",
      "execute_plan(2)\n",
      "```\n",
      "\n",
      "Answer:  Yes.\n",
      "Answer:  Yes.\n",
      "Answer:  ```\n",
      "import numpy as np\n",
      "\n",
      "reset_reward() \n",
      "set_l2_distance_reward(\"dish rack\", \"dish plate\")\n",
      "set_obj_orientation_reward(\"dish plate\", 0, 0)\n",
      "set_obj_position_reward(\"dish plate\", -0.04, 0.03, 0.82)\n",
      "set_obj_position_reward(\"dish rack\", 0, 0.06, 0.82)\n",
      "\n",
      "execute_plan(2)\n",
      "```\n",
      "\n",
      "Answer:  Yes.\n",
      "Answer:  Yes.\n",
      "Answer:  ```\n",
      "import numpy as np\n",
      "\n",
      "reset_reward()\n",
      "set_l2_distance_reward(\"dish rack\", \"dish plate\")\n",
      "set_obj_orientation_reward(\"dish plate\", 0, 0)\n",
      "set_obj_position_reward(\"dish plate\", 0, 0, 0.28)\n",
      "\n",
      "execute_plan(2)\n",
      "```\n",
      "Answer:  Yes.\n",
      "Answer:  Yes.\n",
      "Answer:  ```\n",
      "import numpy as np\n",
      "\n",
      "reset_reward()\n",
      "set_l2_distance_reward(\"dish rack\", \"dish plate\")\n",
      "set_obj_position_reward(\"dish plate\", 0, -0.05, 0.28)\n",
      "\n",
      "execute_plan(2)\n",
      "```\n",
      "This code sets the reward to minimize the distance between the dish rack and the dish plate. It also encourages the dish plate to be positioned close to the target position inside the dish rack. The execution plan runs for 2 seconds.\n",
      "\n",
      "Answer:  Yes.\n",
      "Answer:  Yes.\n",
      "Answer:  ```\n",
      "import numpy as np\n",
      "\n",
      "reset_reward()\n",
      "set_l2_distance_reward(\"dish rack\", \"dish plate\")\n",
      "set_obj_orientation_reward(\"dish plate\", 0, 0)\n",
      "set_obj_position_reward(\"dish plate\", 0, -0.06, 0)\n",
      "\n",
      "execute_plan(2)\n",
      "```\n",
      "Answer:  Yes.\n",
      "Answer:  Yes.\n",
      "Answer:  ```\n",
      "import numpy as np\n",
      "\n",
      "reset_reward()\n",
      "set_l2_distance_reward(\"dish plate\", \"dish rack\")\n",
      "set_obj_position_reward(\"dish plate\", 0, -0.06, -0.14)\n",
      "\n",
      "execute_plan(2)\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(20):\n",
    "    engine = \"gpt-3.5-turbo\"\n",
    "    llm = ChatGPT(model_engine=engine)\n",
    "\n",
    "    prompt = '''\n",
    "    We have a manipulator and we want you to help plan how it should move to perform tasks using the following template:\n",
    "    The rack has slots aligned along the y-axis\n",
    "\n",
    "    The plate size is {x:0.14, y:0.02, z:0.14}m.\n",
    "    The dish rack size is {x:0.17, y:0.07, z:0.28}m.\n",
    "    The center of mass of Plate2 is placed in a rack where the coordinate is {x: 0.9, y: 0.29, z: 0.82}m.\n",
    "    The center of mass of Plate3 is placed in a rack where the coordinate is {x: 0.9, y: 0.23, z: 0.82}m.\n",
    "    The rack has slots aligned along the y-axis.\n",
    "\n",
    "    Place a dish plate into a dish rack, and tell me the range.\n",
    "\n",
    "    [start of plan]\n",
    "    [optional] To perform this task, the manipulator's gripper should move close to dish plate\n",
    "    [optional] dish plate should be close to dish rack.\n",
    "    [optional] The center of mass of dish rack is placed on {x:0.9, y:0.35, z:0.82}m.\n",
    "    [optional] The range of the dish plate is able to be placed in the dish rack {MINIMUM RANGE: 0.0, 0.0, 0.0}m and {MAXIMUM RANGE: 0.0, 0.0, 0.0}.\n",
    "    [end of plan]\n",
    "\n",
    "    Rules:\n",
    "    1. If you see phrases like {MINIMUM RANGE: default x value, default y value, default z value}, {MAXIMUM RANGE: default x value, default y value, default z value}\n",
    "    replace the entire phrase with a numerical value.\n",
    "    2. If you see [optional], it means you only add that line if necessary for the task, otherwise remove that line.\n",
    "    3. Do not invent new objects not listed here.\n",
    "    4. I will tell you a behavior/skill/task that I want the manipulator to perform and you will provide the full plan,\n",
    "    even if you may only need to change a few lines. Always start the description with [start of plan] and end it with [end of plan].\n",
    "    5. You can assume that the robot is capable of doing anything, even for the most challenging task.\n",
    "    6. Your plan should be as close to the provided template as possible. Do not include additional details.\n",
    "    7. The robot is facing towards positive x-axis, positive y-axis is to the left of the robot, positive z-axis is upward.\n",
    "    8. Objects are free to move around unless a command is given.\n",
    "    9. Answer the range {MINIMUM RANGE: 0.0, 0.0, 0.0}m and {MAXIMUM RANGE: 0.0, 0.0, 0.0} where a dish is able to be placed in the dish rack.\n",
    "    If you understand, say Yes.\n",
    "    '''\n",
    "\n",
    "    response = llm.get_answer(prompt)\n",
    "    print(\"Answer: \", response)\n",
    "\n",
    "\n",
    "    # llm = ChatGPT(model_engine=engine)\n",
    "    prompt = '''\n",
    "    We have a plan of a robot arm with gripper to place objects and we want you to turn that into the corresponding reward specifying program with following functions:\n",
    "\n",
    "    ```\n",
    "    def set_l2_distance_reward(name_obj_A, name_obj_B)\n",
    "    ```\n",
    "    where name_obj_A and name_obj_B are selected from ['dish rack', 'dish plate'].\n",
    "    This term sets a reward for minimizing l2_distance between name_obj_A and name_obj_B so they get closer to each other.\n",
    "\n",
    "    ```\n",
    "    def set_obj_orientation_reward(name_obj, x_axis_rotation_radians, z_axis_rotation_radians)\n",
    "    ```\n",
    "    this term encourages the orientation of name_obj to be close to the target.\n",
    "\n",
    "    ```\n",
    "    def execute_plan(duration=2)\n",
    "    ```\n",
    "    This function sends the parameters to the robot and execute the plan for `duration` seconds, default to be 2\n",
    "\n",
    "    ```\n",
    "    def set_obj_position_reward(name_obj, x_offset, y_offset, z_height)\n",
    "    ```\n",
    "    this term encourages the position of name_obj to be close to the specified target position.\n",
    "\n",
    "    ```\n",
    "    def reset_reward()\n",
    "    ```\n",
    "    This function resets the reward to default values.\n",
    "\n",
    "    This is the first plan for a new task.\n",
    "\n",
    "    Example answer code:\n",
    "    ```\n",
    "    import numpy as np\n",
    "\n",
    "    reset_reward() # This is a new task so reset reward; otherwise we don't need it\n",
    "    set_l2_distance_reward(\"dish rack\", \"dish plate\")\n",
    "    set_obj_orientation_reward(\"dish plate\", np.deg2rad(30), 0)\n",
    "    set_obj_position_reward(\"dish plate\", 0, 0, 1.0)\n",
    "\n",
    "    execute_plan(4)\n",
    "    ```\n",
    "\n",
    "    Remember:\n",
    "    1. Always format the code in code blocks. In your response execute_plan should be called exactly once at the end.\n",
    "    2. Do not invent new functions or classes. The only allowed functions you can call are the ones listed above. Do not leave unimplemented code blocks in your response.\n",
    "    3. The only allowed library is numpy. Do not import or use any other library.\n",
    "    4. If you are not sure what value to use, just use your best judge. Do not use None for anything.\n",
    "    5. Do not calculate the position or direction of any object (except for the ones provided above). Just use a number directly based on your best guess.\n",
    "    6. You do not need to make the robot do extra things not mentioned in the plan such as stopping the robot.\n",
    "\n",
    "    If you understand, say Yes.\n",
    "    '''\n",
    "    response = llm.get_answer(prompt)\n",
    "    print(\"Answer: \", response)\n",
    "\n",
    "\n",
    "    prompt = \"Put a dish plate into a dish rack\"\n",
    "    \n",
    "    response = llm.get_answer(prompt)\n",
    "    print(\"Answer: \", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = np.array([0.9,0.35,0.82])\n",
    "# Init viewer\n",
    "env.init_viewer(viewer_title='UR5e with RG2 gripper',viewer_width=1200,viewer_height=800,\n",
    "                viewer_hide_menus=True, MODE='window')\n",
    "env.update_viewer(azimuth=30,distance=3.0,elevation=-30,lookat=[1.0,0.0,0.71],\n",
    "                VIS_TRANSPARENT=False,VIS_CONTACTPOINT=False,\n",
    "                contactwidth=0.05,contactheight=0.05,contactrgba=np.array([1,0,0,1]),\n",
    "                VIS_JOINT=False,jointlength=0.25,jointwidth=0.05,jointrgba=[0.2,0.6,0.8,0.6])\n",
    "\n",
    "pcd_tick = 0\n",
    "\n",
    "# Reset\n",
    "env.reset()\n",
    "init_ur_q = np.array([np.deg2rad(-90), np.deg2rad(-130), np.deg2rad(120), np.deg2rad(100), np.deg2rad(45), np.deg2rad(-90)])\n",
    "env.forward(q=init_ur_q, joint_idxs=env.idxs_forward)\n",
    "initial_xyz = env.get_p_body('tcp_link')\n",
    "print(env.get_p_body('tcp_link'))\n",
    "tick,max_sec = 0,2\n",
    "\n",
    "\n",
    "# Target dish\n",
    "env.model.joint(env.model.body('kitchen-plate').jntadr[0]).qpos0[:3] = np.array([res[0], res[1], 0.82+0.25])\n",
    "env.model.joint(env.model.body('kitchen-plate').jntadr[0]).qpos0[3:] = r2quat(rpy2r(np.radians([0, 90, 90])))\n",
    "while env.get_sim_time() <= max_sec:\n",
    "    env.step(ctrl=init_ur_q,ctrl_idxs=env.idxs_step)\n",
    "    if not env.is_viewer_alive(): break\n",
    "    # Render\n",
    "    if env.loop_every(HZ=20):\n",
    "        # Compute some poses\n",
    "        p_tcp,R_tcp = env.get_pR_body(body_name='tcp_link')\n",
    "        p_cam,R_cam = env.get_pR_body(body_name='camera_center')\n",
    "        p_base,R_base = env.get_pR_body(body_name='base')\n",
    "        # Get PCD from a specific view\n",
    "        p_ego  = p_cam\n",
    "        p_trgt = p_cam + R_cam[:,2] + np.array([0,0,-0.1])\n",
    "        rgb_img,depth_img,pcd,xyz_img = env.get_egocentric_rgb_depth_pcd(\n",
    "            p_ego=p_ego,p_trgt=p_trgt,rsz_rate=40,fovy=45,BACKUP_AND_RESTORE_VIEW=True)\n",
    "        env.render(render_every=1)\n",
    "plt.imshow(rgb_img); plt.axis('off'); plt.show()\n",
    "plt.imshow(depth_img); plt.axis('off'); plt.show()\n",
    "p_dish2, R_dish2 = env.get_pR_body(body_name='kitchen-plate-2')\n",
    "\n",
    "# Close viewer\n",
    "env.close_viewer()\n",
    "print (\"Done. Tick:[%d] Time:[%.2f]sec\"%(env.tick,env.get_sim_time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

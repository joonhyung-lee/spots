{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semi-autonomous Teleoperation Demo : Place task in `Kitchen Plate` scene with `small size dish rack`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse `Realistic Scene`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuJoCo version:[2.3.3]\n"
     ]
    }
   ],
   "source": [
    "import mujoco #,cv2,pyvista\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append('../../../')\n",
    "from utils.mujoco_parser import MuJoCoParserClass\n",
    "from baselines.rl.dlpg.buffer import BufferClass\n",
    "from baselines.rl.dlpg.dlpg import DeepLatentPolicyGradient\n",
    "from utils.util import sample_xyzs,rpy2r,r2rpy,r2quat,compute_view_params,get_interp_const_vel_traj, printmd\n",
    "np.set_printoptions(precision=2,suppress=True,linewidth=100)\n",
    "plt.rc('xtick',labelsize=6); plt.rc('ytick',labelsize=6)\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "\n",
    "def torch2np(x_torch):\n",
    "    if x_torch is None:\n",
    "        x_np = None\n",
    "    else:\n",
    "        x_np = x_torch.detach().cpu().numpy()\n",
    "    return x_np\n",
    "def np2torch(x_np,device='cpu'):\n",
    "    if x_np is None:\n",
    "        x_torch = None\n",
    "    else:\n",
    "        x_torch = torch.tensor(x_np,dtype=torch.float32,device=device)\n",
    "    return x_torch\n",
    "\n",
    "print (\"MuJoCo version:[%s]\"%(mujoco.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_path = '../../../asset/scene_kitchen_dish_rack_black.xml'\n",
    "env    = MuJoCoParserClass(name='Place task scene: Plate table',rel_xml_path=xml_path,VERBOSE=False, MODE='window')\n",
    "dlpg   = DeepLatentPolicyGradient(xdim=2, cdim=6, zdim=5, hdims=[64,64], actv_enc=nn.LeakyReLU())\n",
    "buffer = BufferClass(xdim=2, cdim=6, buffer_limit=1000)\n",
    "\n",
    "# Move tables and robot base\n",
    "env.model.body('base_table').pos = np.array([0,0,0])\n",
    "env.model.body('base').pos = np.array([-10,0,0.79])\n",
    "env.model.body('avoiding_object_table').pos = np.array([0.38+0.45,0,0])\n",
    "env.model.body('right_object_table').pos = np.array([-0.05,-0.80,0])\n",
    "env.model.body('left_object_table').pos = np.array([-1.5,0.80,0])\n",
    "\n",
    "# Place objects\n",
    "obj_box_names = [body_name for body_name in env.body_names\n",
    "             if body_name is not None and (body_name.startswith(\"obj_box\"))]\n",
    "n_box_obj = len(obj_box_names)\n",
    "env.place_objects_random(n_obj=n_box_obj, obj_names=obj_box_names, x_range=[0.80, 1.15], y_range=[-3.15, -2.15], COLORS=False, VERBOSE=True)\n",
    "\n",
    "jntadr_mug_cup = env.model.body('mug_cup').jntadr[0]\n",
    "env.model.joint(jntadr_mug_cup).qpos0[:3] = np.array([ 10, -0.3, 0.85])\n",
    "env.model.joint(jntadr_mug_cup).qpos0[3:] = r2quat(rpy2r(np.radians([0, 0, np.random.rand() * 360])))\n",
    "\n",
    "jntadr_tray = env.model.body('tray').jntadr[0]\n",
    "env.model.joint(jntadr_tray).qpos0[:3] = np.array([10,-0.3,0.80])\n",
    "env.model.joint(jntadr_tray).qpos0[3:] = r2quat(rpy2r(np.radians([0, 0, 0])))\n",
    "\n",
    "jntadr_dish_rack = env.model.body('kitchen-drainer').jntadr[0]\n",
    "pos_dish_rack = np.array([0.9,0.35,0.82])\n",
    "env.model.joint(jntadr_dish_rack).qpos0[:3] = pos_dish_rack\n",
    "dish_rack_random_rot = 0 # np.random.rand() * 360\n",
    "env.model.joint(jntadr_dish_rack).qpos0[3:] = r2quat(rpy2r(np.radians([0, 0, dish_rack_random_rot])))\n",
    "\n",
    "\n",
    "# Target dish\n",
    "env.model.joint(env.model.body('kitchen-plate').jntadr[0]).qpos0[:3] = np.array([0.2, -0.7, 0.8])\n",
    "# Set the dishes\n",
    "env.model.joint(env.model.body('kitchen-plate-2').jntadr[0]).qpos0[:3] = pos_dish_rack + np.array([0.,-0.06, 0.25])\n",
    "env.model.joint(env.model.body('kitchen-plate-2').jntadr[0]).qpos0[3:] = r2quat(rpy2r(np.radians([0, 90, 90])))\n",
    "env.model.joint(env.model.body('kitchen-plate-3').jntadr[0]).qpos0[:3] = pos_dish_rack + np.array([0., -0.12, 0.25])\n",
    "env.model.joint(env.model.body('kitchen-plate-3').jntadr[0]).qpos0[3:] = r2quat(rpy2r(np.radians([0, 90, 90])))\n",
    "env.model.joint(env.model.body('kitchen-plate-4').jntadr[0]).qpos0[:3] = pos_dish_rack + np.array([-3.5, 0., 0.25])\n",
    "env.model.joint(env.model.body('kitchen-plate-4').jntadr[0]).qpos0[3:] = r2quat(rpy2r(np.radians([0, 90, 90])))\n",
    "\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state_trgt [ 0.2 -0.7  0.8  1.   0.   0.   0. ]\n",
      "state_trgt [ 0.2 -0.7  0.8  1.   0.   0.   0. ]\n",
      "state_trgt [ 0.2 -0.7  0.8  1.   0.   0.   0. ]\n",
      "state_trgt [ 0.2 -0.7  0.8  1.   0.   0.   0. ]\n",
      "state_trgt [ 0.2 -0.7  0.8  1.   0.   0.   0. ]\n",
      "state_trgt [ 0.2 -0.7  0.8  1.   0.   0.   0. ]\n",
      "state_trgt [ 0.2 -0.7  0.8  1.   0.   0.   0. ]\n",
      "state_trgt [ 0.2 -0.7  0.8  1.   0.   0.   0. ]\n",
      "state_trgt [ 0.2 -0.7  0.8  1.   0.   0.   0. ]\n",
      "state_trgt [ 0.2 -0.7  0.8  1.   0.   0.   0. ]\n",
      "state_trgt [ 0.2 -0.7  0.8  1.   0.   0.   0. ]\n",
      "state_trgt [ 0.2 -0.7  0.8  1.   0.   0.   0. ]\n",
      "state_trgt [ 0.2 -0.7  0.8  1.   0.   0.   0. ]\n",
      "state_trgt [ 0.2 -0.7  0.8  1.   0.   0.   0. ]\n",
      "state_trgt [ 0.2 -0.7  0.8  1.   0.   0.   0. ]\n",
      "state_trgt [ 0.2 -0.7  0.8  1.   0.   0.   0. ]\n",
      "state_trgt [ 0.2 -0.7  0.8  1.   0.   0.   0. ]\n",
      "state_trgt [ 0.2 -0.7  0.8  1.   0.   0.   0. ]\n",
      "state_trgt [ 0.2 -0.7  0.8  1.   0.   0.   0. ]\n",
      "state_trgt [ 0.2 -0.7  0.8  1.   0.   0.   0. ]\n",
      "state_trgt [ 0.2 -0.7  0.8  1.   0.   0.   0. ]\n",
      "state_trgt [ 0.2 -0.7  0.8  1.   0.   0.   0. ]\n",
      "state_trgt [ 0.2 -0.7  0.8  1.   0.   0.   0. ]\n",
      "state_trgt [ 0.2 -0.7  0.8  1.   0.   0.   0. ]\n",
      "state_trgt [ 0.2 -0.7  0.8  1.   0.   0.   0. ]\n",
      "state_trgt [ 0.2 -0.7  0.8  1.   0.   0.   0. ]\n",
      "state_trgt [ 0.2 -0.7  0.8  1.   0.   0.   0. ]\n",
      "state_trgt [ 0.2 -0.7  0.8  1.   0.   0.   0. ]\n",
      "state_trgt [ 0.2 -0.7  0.8  1.   0.   0.   0. ]\n",
      "state_trgt [ 0.2 -0.7  0.8  1.   0.   0.   0. ]\n",
      "state_trgt [ 0.2 -0.7  0.8  1.   0.   0.   0. ]\n",
      "state_trgt [ 0.2 -0.7  0.8  1.   0.   0.   0. ]\n",
      "state_trgt [ 0.2 -0.7  0.8  1.   0.   0.   0. ]\n",
      "state_trgt [ 0.2 -0.7  0.8  1.   0.   0.   0. ]\n",
      "state_trgt [ 0.2 -0.7  0.8  1.   0.   0.   0. ]\n",
      "state_trgt [ 0.2 -0.7  0.8  1.   0.   0.   0. ]\n",
      "state_trgt [ 0.2 -0.7  0.8  1.   0.   0.   0. ]\n",
      "state_trgt [ 0.2 -0.7  0.8  1.   0.   0.   0. ]\n",
      "state_trgt [ 0.2 -0.7  0.8  1.   0.   0.   0. ]\n",
      "state_trgt [ 0.2 -0.7  0.8  1.   0.   0.   0. ]\n",
      "state_trgt [ 0.2 -0.7  0.8  1.   0.   0.   0. ]\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "GLFW window does not exist but you tried to render.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 85\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[39m# Render\u001b[39;00m\n\u001b[1;32m     84\u001b[0m         \u001b[39mif\u001b[39;00m env\u001b[39m.\u001b[39mloop_every(HZ\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m):\n\u001b[0;32m---> 85\u001b[0m             env\u001b[39m.\u001b[39;49mrender(render_every\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n\u001b[1;32m     87\u001b[0m     \u001b[39m# if (epoch+1)%1000: \u001b[39;00m\n\u001b[1;32m     88\u001b[0m     \u001b[39m#     # Update Policy \u001b[39;00m\n\u001b[1;32m     89\u001b[0m     \u001b[39m#     for i in range(max_update_iter): \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[39m#     print(\"[Iteration:{}][Recon Loss:{}][KL Loss:{}]\".format(i+1,loss_recon_sum.item()/batch_size, loss_kl_sum.item()/batch_size))\u001b[39;00m\n\u001b[1;32m    108\u001b[0m     \u001b[39m#     torch.save(dlpg.cvae.state_dict(),\"./weights/\"+weight_name+\"/\"+weight_name+\"{}.pth\".format(epoch+1))  \u001b[39;00m\n\u001b[1;32m    111\u001b[0m env\u001b[39m.\u001b[39mclose_viewer()\n",
      "File \u001b[0;32m~/towards-interpretable-preference-based-learning/demo/scene/kitchen_with_dish/../../../utils/mujoco_parser.py:283\u001b[0m, in \u001b[0;36mMuJoCoParserClass.render\u001b[0;34m(self, render_every)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mMODE \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mwindow\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    282\u001b[0m     \u001b[39mif\u001b[39;00m ((\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrender_tick \u001b[39m%\u001b[39m render_every) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m) \u001b[39mor\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrender_tick \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m):\n\u001b[0;32m--> 283\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mviewer\u001b[39m.\u001b[39;49mrender()\n\u001b[1;32m    284\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrender_tick \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrender_tick \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    285\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mMODE \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39moffscreen\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/mujoco_viewer/mujoco_viewer.py:309\u001b[0m, in \u001b[0;36mMujocoViewer.render\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    307\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUse \u001b[39m\u001b[39m'\u001b[39m\u001b[39mread_pixels()\u001b[39m\u001b[39m'\u001b[39m\u001b[39m for \u001b[39m\u001b[39m'\u001b[39m\u001b[39moffscreen\u001b[39m\u001b[39m'\u001b[39m\u001b[39m mode.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    308\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_alive:\n\u001b[0;32m--> 309\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\n\u001b[1;32m    310\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mGLFW window does not exist but you tried to render.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    311\u001b[0m \u001b[39mif\u001b[39;00m glfw\u001b[39m.\u001b[39mwindow_should_close(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwindow):\n\u001b[1;32m    312\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "\u001b[0;31mException\u001b[0m: GLFW window does not exist but you tried to render."
     ]
    }
   ],
   "source": [
    "# Init viewer\n",
    "env.init_viewer(viewer_title='UR5e with RG2 gripper',viewer_width=1200,viewer_height=800,\n",
    "                viewer_hide_menus=True, MODE='window')\n",
    "env.update_viewer(azimuth=30,distance=3.0,elevation=-30,lookat=[1.0,0.0,0.71],\n",
    "                  VIS_TRANSPARENT=False,VIS_CONTACTPOINT=False,\n",
    "                  contactwidth=0.05,contactheight=0.05,contactrgba=np.array([1,0,0,1]),\n",
    "                  VIS_JOINT=False,jointlength=0.25,jointwidth=0.05,jointrgba=[0.2,0.6,0.8,0.6])\n",
    "init_ur_q = np.array([np.deg2rad(-90), np.deg2rad(-130), np.deg2rad(120), np.deg2rad(100), np.deg2rad(45), np.deg2rad(-90)])\n",
    "trgt_name       = 'kitchen-plate'\n",
    "obj_name_lst    = ['kitchen-plate-2', 'kitchen-plate-3', 'kitchen-drainer']\n",
    "max_update_iter = 40 \n",
    "max_epochs      = 100 \n",
    "lr              = 1e-3 \n",
    "batch_size      = 128\n",
    "optimizer       = torch.optim.Adam(dlpg.cvae.parameters(),lr=lr, betas=(0.9, 0.99))\n",
    "weight_name = 'test'\n",
    "env.reset()\n",
    "\n",
    "start_tick = 0 \n",
    "end_tick = 2500\n",
    "\n",
    "for epoch in range(max_epochs): \n",
    "    env.reset()\n",
    "    start_tick = 0\n",
    "\n",
    "    # Randomize object poses\n",
    "    x_rand   = np.random.uniform(low=0.7, high=0.9, size=(1))\n",
    "    y_rand   = np.random.uniform(low=-0.2, high=0.2, size=(1))\n",
    "    yaw_rand = np.random.uniform(low=-90, high=90)\n",
    "\n",
    "    random_pose_lst = np.concatenate((x_rand,y_rand,np.array([0.82])),axis=0)\n",
    "\n",
    "    obj_jntadr  = env.model.body('kitchen-drainer').jntadr[0]\n",
    "    obj_qposadr = env.model.jnt_qposadr[obj_jntadr]\n",
    "    env.data.qpos[obj_qposadr:obj_qposadr+3]   = random_pose_lst\n",
    "    env.data.qpos[obj_qposadr+3:obj_qposadr+7] = r2quat(rpy2r(np.radians([0, 0, yaw_rand-90])))\n",
    "\n",
    "    obj_jntadr  = env.model.body('kitchen-plate-2').jntadr[0]\n",
    "    obj_qposadr = env.model.jnt_qposadr[obj_jntadr]\n",
    "    env.data.qpos[obj_qposadr:obj_qposadr+3]   = random_pose_lst+ np.array([0.-np.cos(np.deg2rad(yaw_rand))*0.06,-np.sin(np.deg2rad(yaw_rand))*0.06, 0.25])\n",
    "    env.data.qpos[obj_qposadr+3:obj_qposadr+7] = r2quat(rpy2r(np.radians([0, 90, yaw_rand])))\n",
    "\n",
    "    obj_jntadr  = env.model.body('kitchen-plate-3').jntadr[0]\n",
    "    obj_qposadr = env.model.jnt_qposadr[obj_jntadr]\n",
    "    env.data.qpos[obj_qposadr:obj_qposadr+3]   = random_pose_lst+ np.array([0.-np.cos(np.deg2rad(yaw_rand))*0.12, -np.sin(np.deg2rad(yaw_rand))*0.12, 0.25])\n",
    "    env.data.qpos[obj_qposadr+3:obj_qposadr+7] = r2quat(rpy2r(np.radians([0, 90, yaw_rand])))\n",
    "\n",
    "    # Get observations\n",
    "    p_obj, R_obj = env.get_pR_body(body_name='kitchen-drainer')\n",
    "    quat_obj     = r2quat(R_obj)\n",
    "    state        = np.concatenate((p_obj[:-1],quat_obj))\n",
    "\n",
    "    # Epsilon greedy \n",
    "    epsgrdy = 5*np.exp(max_epochs/20.)\n",
    "    if np.random.rand() < epsgrdy:\n",
    "        trgt_pose  = dlpg.explore()\n",
    "    else: \n",
    "        trgt_pose = torch2np(dlpg.exploit(state))\n",
    "\n",
    "    # Move target object  \n",
    "    trgt_jntadr = env.model.body(trgt_name).jntadr[0]\n",
    "    trgt_qposadr= env.model.jnt_qposadr[trgt_jntadr] \n",
    "    env.data.qpos[trgt_qposadr:trgt_qposadr+2]   = trgt_pose\n",
    "    env.data.qpos[trgt_qposadr+2:trgt_qposadr+3]   = 0.82 # 0.82\n",
    "    env.data.qpos[trgt_qposadr+3:trgt_qposadr+7] = r2quat(rpy2r(np.radians([0, 90, yaw_rand]))) \n",
    "\n",
    "    # Get target state\n",
    "    p_trgt, R_trgt = env.get_pR_body(body_name=trgt_name)\n",
    "    quat_trgt      = r2quat(R_trgt)\n",
    "    state_trgt     = np.concatenate((p_trgt,quat_trgt))\n",
    "    print(\"state_trgt\",state_trgt)\n",
    "    # Get reward \n",
    "    reward = dlpg.get_reward(state_trgt)\n",
    "\n",
    "    # Save Buffer \n",
    "    buffer.store(x=trgt_pose, c=state, reward=reward)\n",
    "\n",
    "    while env.tick - start_tick < end_tick:\n",
    "        env.forward(q=init_ur_q, joint_idxs=env.idxs_forward)\n",
    "        env.step(ctrl=init_ur_q,ctrl_idxs=env.idxs_step)\n",
    "\n",
    "        # Render\n",
    "        if env.loop_every(HZ=100):\n",
    "            env.render(render_every=10)\n",
    "\n",
    "    if (epoch+1)%1000: \n",
    "        # Update Policy \n",
    "        for i in range(max_update_iter): \n",
    "            loss_recon_sum=0;loss_kl_sum=0;n_batch_sum=0\n",
    "            batch = buffer.sample_batch(batch_size=batch_size)\n",
    "            x_batch, c_batch, reward_batch = batch[\"x\"], batch[\"c\"], batch[\"reward\"]\n",
    "            total_loss_out,loss_info = dlpg.cvae.loss_total(x           = x_batch, \n",
    "                                                        c               = c_batch, \n",
    "                                                        q               = reward_batch, \n",
    "                                                        LOSS_TYPE       = 'L1+L2',\n",
    "                                                        recon_loss_gain = 10,\n",
    "                                                        beta            = 0.01,\n",
    "                                                        STOCHASTICITY   = True)\n",
    "            optimizer.zero_grad()\n",
    "            total_loss_out.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_recon_sum = loss_recon_sum + batch_size*loss_info['loss_recon_out']\n",
    "            loss_kl_sum    = loss_kl_sum + batch_size*loss_info['loss_kl_out']\n",
    "            n_batch_sum    = n_batch_sum + batch_size   \n",
    "        print(\"[Iteration:{}][Recon Loss:{}][KL Loss:{}]\".format(i+1,loss_recon_sum.item()/batch_size, loss_kl_sum.item()/batch_size))\n",
    "        torch.save(dlpg.cvae.state_dict(),\"./weights/\"+weight_name+\"/\"+weight_name+\"{}.pth\".format(epoch+1))  \n",
    "\n",
    "\n",
    "env.close_viewer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

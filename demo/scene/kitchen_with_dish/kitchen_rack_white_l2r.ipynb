{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semi-autonomous Teleoperation Demo : Place task in `Kitchen Plate` scene with `small size dish rack`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse `Realistic Scene`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuJoCo version:[2.3.3]\n"
     ]
    }
   ],
   "source": [
    "import mujoco#,cv2,pyvista\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append('../../../')\n",
    "from utils.mujoco_parser import MuJoCoParserClass\n",
    "\n",
    "from utils.util import sample_xyzs,rpy2r,r2rpy,r2quat,compute_view_params,get_interp_const_vel_traj, printmd\n",
    "np.set_printoptions(precision=2,suppress=True,linewidth=100)\n",
    "plt.rc('xtick',labelsize=6); plt.rc('ytick',labelsize=6)\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "print (\"MuJoCo version:[%s]\"%(mujoco.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window\n"
     ]
    }
   ],
   "source": [
    "xml_path = '../../../asset/scene_kitchen_dish_rack_black.xml'\n",
    "env = MuJoCoParserClass(name='Place task scene: Plate table',rel_xml_path=xml_path,VERBOSE=False, MODE='window')\n",
    "print(env.MODE)\n",
    "\n",
    "# Move tables and robot base\n",
    "env.model.body('base_table').pos = np.array([0,0,0])\n",
    "env.model.body('base').pos = np.array([0.18,0,0.79])\n",
    "env.model.body('avoiding_object_table').pos = np.array([0.38+0.45,0,0])\n",
    "env.model.body('right_object_table').pos = np.array([-0.05,-0.80,0])\n",
    "env.model.body('left_object_table').pos = np.array([-1.5,0.80,0])\n",
    "\n",
    "# Place objects\n",
    "obj_box_names = [body_name for body_name in env.body_names\n",
    "             if body_name is not None and (body_name.startswith(\"obj_box\"))]\n",
    "n_box_obj = len(obj_box_names)\n",
    "env.place_objects_random(n_obj=n_box_obj, obj_names=obj_box_names, x_range=[0.80, 1.15], y_range=[-3.15, -2.15], COLORS=False, VERBOSE=True)\n",
    "\n",
    "jntadr_mug_cup = env.model.body('mug_cup').jntadr[0]\n",
    "env.model.joint(jntadr_mug_cup).qpos0[:3] = np.array([ 0.9, -0.3, 0.85])\n",
    "env.model.joint(jntadr_mug_cup).qpos0[3:] = r2quat(rpy2r(np.radians([0, 0, np.random.rand() * 360])))\n",
    "\n",
    "jntadr_tray = env.model.body('tray').jntadr[0]\n",
    "env.model.joint(jntadr_tray).qpos0[:3] = np.array([0.9,-0.3,0.80])\n",
    "# env.model.joint(jntadr_tray).qpos0[3:] = r2quat(rpy2r(np.radians([0, 0, 0])))\n",
    "\n",
    "jntadr_dish_rack = env.model.body('kitchen-drainer').jntadr[0]\n",
    "pos_dish_rack = np.array([0.9,0.35,0.82])\n",
    "env.model.joint(jntadr_dish_rack).qpos0[:3] = pos_dish_rack\n",
    "dish_rack_random_rot = 0 # np.random.rand() * 360\n",
    "env.model.joint(jntadr_dish_rack).qpos0[3:] = r2quat(rpy2r(np.radians([0, 0, dish_rack_random_rot])))\n",
    "\n",
    "\n",
    "# Target dish\n",
    "env.model.joint(env.model.body('kitchen-plate').jntadr[0]).qpos0[:3] = np.array([0.2, -0.7, 0.8])\n",
    "# Set the dishes\n",
    "env.model.joint(env.model.body('kitchen-plate-2').jntadr[0]).qpos0[:3] = pos_dish_rack + np.array([0.,-0.06, 0.25])\n",
    "env.model.joint(env.model.body('kitchen-plate-2').jntadr[0]).qpos0[3:] = r2quat(rpy2r(np.radians([0, 90, 90])))\n",
    "env.model.joint(env.model.body('kitchen-plate-3').jntadr[0]).qpos0[:3] = pos_dish_rack + np.array([0., -0.12, 0.25])\n",
    "env.model.joint(env.model.body('kitchen-plate-3').jntadr[0]).qpos0[3:] = r2quat(rpy2r(np.radians([0, 90, 90])))\n",
    "env.model.joint(env.model.body('kitchen-plate-4').jntadr[0]).qpos0[:3] = pos_dish_rack + np.array([-3.5, 0., 0.25])\n",
    "env.model.joint(env.model.body('kitchen-plate-4').jntadr[0]).qpos0[3:] = r2quat(rpy2r(np.radians([0, 90, 90])))\n",
    "\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import openai \n",
    "import os \n",
    "openai.api_key = 'your key' \n",
    "\n",
    "def gauss_2d(mu, sigma=0.01):\n",
    "    x = random.gauss(mu[0], sigma)\n",
    "    y = random.gauss(mu[1], sigma)\n",
    "    return (x, y)\n",
    "\n",
    "\n",
    "class ChatGPT():\n",
    "    def __init__ (self, model_engine='text-davinci-003'):\n",
    "        self.model_engine = model_engine\n",
    "        self.msg_history_turbo = []\n",
    "        self.msg_history_davinci = \"\"\n",
    "        self.role = 'user'\n",
    "        \n",
    "    def get_answer(self, prompt=None):\n",
    "        if self.model_engine == 'gpt-3.5-turbo':\n",
    "            self.msg_history_turbo.append({\"role\": self.role, \"content\":prompt})\n",
    "            response   = openai.ChatCompletion.create(\n",
    "            model      = self.model_engine,\n",
    "            messages   = self.msg_history_turbo)\n",
    "            reply_text = response['choices'][0]['message']['content']\n",
    "            self.msg_history_turbo.append({\"role\":\"assistant\", \"content\":reply_text})\n",
    "\n",
    "        elif self.model_engine == 'text-davinci-003': \n",
    "            self.msg_history_davinci += \"You: \"+prompt \n",
    "            response   = openai.Completion.create(\n",
    "            engine     = self.model_engine,\n",
    "            prompt     = self.msg_history_davinci,\n",
    "            max_tokens = 512,\n",
    "            temperature= 1.0,\n",
    "            n          = 1,\n",
    "            #stop       = [\"You:\", \"AI:\"]\n",
    "            )\n",
    "            reply_text = response.choices[0].text.strip().replace('Answer: ', '')\n",
    "            self.msg_history_davinci+=\"\\n\"+\"AI: \"+reply_text+\"\\n\"\n",
    "        # print(\"ChatGPT: {}\".format(reply_text))\n",
    "        return reply_text\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:  Yes.\n",
      "Answer:  Yes.\n",
      "Answer:  ```\n",
      "import numpy as np\n",
      "\n",
      "reset_reward() # This is a new task so reset reward; otherwise we don't need it\n",
      "set_l2_distance_reward(\"dish rack\", \"dish plate\")\n",
      "set_obj_orientation_reward(\"dish plate\", 0, 0)\n",
      "set_obj_position_reward(\"dish plate\", 0, 0, 0.2)\n",
      "\n",
      "execute_plan(2)\n",
      "```\n",
      "Answer:  Yes.\n",
      "Answer:  Yes.\n",
      "Answer:  ```\n",
      "import numpy as np\n",
      "\n",
      "reset_reward()\n",
      "set_l2_distance_reward(\"dish rack\", \"dish plate\")\n",
      "set_obj_orientation_reward(\"dish plate\", np.deg2rad(0), 0)\n",
      "set_obj_position_reward(\"dish plate\", 0, 0, 0.0)\n",
      "\n",
      "execute_plan(2)\n",
      "```\n",
      "\n",
      "Answer:  Yes\n",
      "Answer:  Yes\n",
      "Answer:  ```\n",
      "import numpy as np\n",
      "\n",
      "reset_reward()\n",
      "set_l2_distance_reward(\"dish plate\", \"dish rack\")\n",
      "set_obj_orientation_reward(\"dish plate\", 0, 0)\n",
      "set_obj_position_reward(\"dish plate\", 0.92, -0.04, 0.79)\n",
      "\n",
      "execute_plan(2)\n",
      "```\n",
      "Answer:  Yes.\n",
      "Answer:  Yes.\n",
      "Answer:  ```\n",
      "reset_reward()\n",
      "set_l2_distance_reward(\"dish plate\", \"dish rack\")\n",
      "set_obj_orientation_reward(\"dish plate\", 0, 0)\n",
      "set_obj_position_reward(\"dish plate\", 0.01, 0.1, 0.07)\n",
      "\n",
      "execute_plan(2)\n",
      "```\n",
      "This code sets the reward for minimizing the distance between the dish plate and the dish rack, encouraging the dish plate to be oriented correctly, and also encourages the dish plate to be positioned close to the desired target position. The `execute_plan` function is then called to execute the plan for 2 seconds.\n",
      "Answer:  Yes.\n",
      "Answer:  Yes.\n",
      "Answer:  ```\n",
      "import numpy as np\n",
      "\n",
      "reset_reward()\n",
      "set_l2_distance_reward(\"dish rack\", \"dish plate\")\n",
      "set_obj_orientation_reward(\"dish plate\", np.deg2rad(0), 0)  # No rotation needed\n",
      "set_obj_position_reward(\"dish plate\", 0, 0.1, 0.2)  # Place the plate in the middle slot of the rack\n",
      "\n",
      "execute_plan(2)\n",
      "```\n",
      "Note: The values for `x_offset`, `y_offset`, and `z_height` in `set_obj_position_reward` are approximate and can be adjusted based on the actual dimensions and position of the objects. Similarly, the duration of execution in `execute_plan` can be adjusted for the desired speed of movement.\n",
      "Answer:  Yes.\n",
      "Answer:  Yes.\n",
      "Answer:  ```\n",
      "import numpy as np\n",
      "\n",
      "reset_reward()\n",
      "set_l2_distance_reward(\"dish rack\", \"dish plate\")\n",
      "set_obj_orientation_reward(\"dish plate\", 0, 0)\n",
      "set_obj_position_reward(\"dish plate\", -0.03, 0, 1.04)\n",
      "\n",
      "execute_plan(2)\n",
      "```\n",
      "\n",
      "Answer:  Yes.\n",
      "Answer:  Yes.\n",
      "Answer:  ```\n",
      "import numpy as np\n",
      "\n",
      "reset_reward()\n",
      "set_l2_distance_reward(\"dish rack\", \"dish plate\")\n",
      "set_obj_orientation_reward(\"dish plate\", 0, 0)\n",
      "set_obj_position_reward(\"dish plate\", 0, 0.05, 1.0)\n",
      "\n",
      "execute_plan(2)\n",
      "```\n",
      "\n",
      "This code sets up the reward functions to encourage the dish plate to be close to the dish rack, have a desired orientation, and be positioned correctly. The plan is then executed for 2 seconds to perform the task.\n",
      "Answer:  Yes\n",
      "Answer:  Yes\n",
      "Answer:  ```\n",
      "import numpy as np\n",
      "\n",
      "reset_reward()\n",
      "set_l2_distance_reward(\"dish plate\", \"dish rack\")\n",
      "set_obj_orientation_reward(\"dish plate\", 0, 0)\n",
      "set_obj_position_reward(\"dish plate\", 0, 0, 0) \n",
      "\n",
      "execute_plan(2)\n",
      "```\n",
      "\n",
      "Answer:  Yes.\n",
      "Answer:  Yes.\n",
      "Answer:  ```\n",
      "import numpy as np\n",
      "\n",
      "reset_reward()\n",
      "set_l2_distance_reward(\"dish rack\", \"dish plate\")\n",
      "set_obj_orientation_reward(\"dish plate\", 0, 0)\n",
      "set_obj_position_reward(\"dish plate\", 0, 0, 0)\n",
      "\n",
      "execute_plan(2)\n",
      "```\n",
      "\n",
      "Answer:  Yes.\n",
      "Answer:  Yes.\n",
      "Answer:  ```\n",
      "import numpy as np\n",
      "\n",
      "reset_reward()\n",
      "set_obj_position_reward(\"dish plate\", 0.0, 0.0, 0.0)\n",
      "set_obj_orientation_reward(\"dish plate\", 0, 0)\n",
      "\n",
      "set_obj_position_reward(\"dish rack\", 0.0, 0.0, 0.0)\n",
      "set_obj_orientation_reward(\"dish rack\", 0, 0)\n",
      "\n",
      "set_l2_distance_reward(\"dish plate\", \"dish rack\")\n",
      "\n",
      "execute_plan(2)\n",
      "```\n",
      "Answer:  Yes, I understand.\n",
      "Answer:  Yes, I understand.\n",
      "Answer:  ```\n",
      "import numpy as np\n",
      "\n",
      "reset_reward()\n",
      "set_l2_distance_reward(\"dish rack\", \"dish plate\")\n",
      "set_obj_orientation_reward(\"dish plate\", 0, 0)\n",
      "set_obj_position_reward(\"dish plate\", 0.93, 0.35, 0.82)\n",
      "\n",
      "execute_plan(2)\n",
      "```\n",
      "\n",
      "The code sets the desired rewards for placing a dish plate into a dish rack. The `set_l2_distance_reward` function encourages the dish plate and dish rack to get closer to each other, while the `set_obj_orientation_reward` function encourages the dish plate to have a specific orientation (in this case, no rotation around the x and z axes). Lastly, the `set_obj_position_reward` function specifies the target position for the dish plate to be placed at.\n",
      "\n",
      "Executing the plan for 2 seconds will allow the robot to perform the task of putting the dish plate into the dish rack.\n",
      "Answer:  Yes, I understand.\n",
      "Answer:  Yes, I understand.\n",
      "Answer:  [start of plan]\n",
      "import numpy as np\n",
      "\n",
      "reset_reward()\n",
      "set_l2_distance_reward(\"dish rack\", \"dish plate\")\n",
      "set_obj_orientation_reward(\"dish plate\", 0, 0)\n",
      "set_obj_position_reward(\"dish plate\", 0, 0, 0.82)\n",
      "\n",
      "execute_plan(2)\n",
      "[end of plan]\n",
      "Answer:  Yes.\n",
      "Answer:  Yes.\n",
      "Answer:  ```\n",
      "import numpy as np\n",
      "\n",
      "reset_reward() \n",
      "set_l2_distance_reward(\"dish rack\", \"dish plate\")\n",
      "set_obj_orientation_reward(\"dish plate\", 0, 0) \n",
      "set_obj_position_reward(\"dish plate\", 0.11, 0, 0.2)\n",
      "\n",
      "execute_plan(2)\n",
      "```\n",
      "Answer:  Yes.\n",
      "Answer:  Yes.\n",
      "Answer:  ```\n",
      "import numpy as np\n",
      "\n",
      "reset_reward()\n",
      "set_l2_distance_reward(\"dish plate\", \"dish rack\")\n",
      "set_obj_orientation_reward(\"dish plate\", 0, 0)\n",
      "set_obj_position_reward(\"dish plate\", 0, 0, 0)\n",
      "\n",
      "execute_plan(2)\n",
      "```\n",
      "\n",
      "Answer:  Yes.\n",
      "Answer:  Yes.\n",
      "Answer:  ```\n",
      "import numpy as np\n",
      "\n",
      "reset_reward()\n",
      "set_l2_distance_reward(\"dish rack\", \"dish plate\")\n",
      "set_obj_orientation_reward(\"dish plate\", 0, 0)\n",
      "set_obj_position_reward(\"dish plate\", 0.81, 0.39, 0.82)\n",
      "\n",
      "execute_plan(2)\n",
      "```\n",
      "\n",
      "Answer:  Yes.\n",
      "Answer:  Yes.\n",
      "Answer:  ```\n",
      "import numpy as np\n",
      "\n",
      "reset_reward()\n",
      "set_l2_distance_reward(\"dish rack\", \"dish plate\")\n",
      "set_obj_orientation_reward(\"dish plate\", 0, 0)\n",
      "set_obj_position_reward(\"dish plate\", 0, 0.17, 0.82)\n",
      "\n",
      "execute_plan(2)\n",
      "```\n",
      "Answer:  Yes.\n",
      "Answer:  Yes.\n",
      "Answer:  ```\n",
      "import numpy as np\n",
      "\n",
      "reset_reward()\n",
      "set_l2_distance_reward(\"dish rack\", \"dish plate\")\n",
      "set_obj_orientation_reward(\"dish plate\", 0, 0)\n",
      "set_obj_position_reward(\"dish plate\", -0.01, 0, 0.3)\n",
      "\n",
      "execute_plan(4)\n",
      "```\n",
      "Note: \n",
      "- The l2_distance reward minimizes the distance between the dish rack and the dish plate, encouraging them to get closer to each other.\n",
      "- The obj_orientation_reward encourages the dish plate to be oriented in its default position (no rotation).\n",
      "- The obj_position_reward encourages the dish plate to be positioned slightly to the left of the dish rack, at a height of 0.3 meters.\n",
      "- The execute_plan function is called for a duration of 4 seconds, allowing the robot to perform the task within that timeframe.\n",
      "Answer:  Yes.\n",
      "Answer:  Yes.\n",
      "Answer:  ```\n",
      "import numpy as np\n",
      "\n",
      "reset_reward() # This is a new task so reset reward; otherwise we don't need it\n",
      "set_l2_distance_reward(\"dish rack\", \"dish plate\")\n",
      "set_obj_orientation_reward(\"dish plate\", 0, 0)\n",
      "set_obj_position_reward(\"dish plate\", -0.03, 0, 0.12)\n",
      "\n",
      "execute_plan(2)\n",
      "```\n",
      "\n",
      "Answer:  Yes.\n",
      "Answer:  Yes.\n",
      "Answer:  ```python\n",
      "import numpy as np\n",
      "\n",
      "reset_reward()\n",
      "set_l2_distance_reward(\"dish rack\", \"dish plate\")\n",
      "set_obj_position_reward(\"dish plate\", 0, 0, 0.2)\n",
      "\n",
      "execute_plan(2)\n",
      "```\n",
      "\n",
      "Answer:  Yes.\n",
      "Answer:  Yes.\n",
      "Answer:  ```\n",
      "import numpy as np\n",
      "\n",
      "reset_reward() \n",
      "set_l2_distance_reward(\"dish rack\", \"dish plate\")\n",
      "set_obj_orientation_reward(\"dish plate\", np.deg2rad(0), 0)\n",
      "set_obj_position_reward(\"dish plate\", 0.11, -0.05, 0.82)\n",
      "\n",
      "execute_plan(2)\n",
      "```\n",
      "Note: \n",
      "- The dish plate is placed with an orientation of 0 degrees around the x-axis and 0 degrees around the z-axis.\n",
      "- The dish plate is positioned in the dish rack with an offset of 0.11m along the x-axis, -0.05m along the y-axis, and at a height of 0.82m. \n",
      "- The plan is executed for a duration of 2 seconds.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(20):\n",
    "    engine = \"gpt-3.5-turbo\"\n",
    "    llm = ChatGPT(model_engine=engine)\n",
    "\n",
    "    prompt = '''\n",
    "    We have a manipulator and we want you to help plan how it should move to perform tasks using the following template:\n",
    "    The rack has slots aligned along the y-axis\n",
    "\n",
    "    The plate size is {x:0.14, y:0.02, z:0.14}m.\n",
    "    The dish rack size is {x:0.11, y:0.2, z:0.22}m.\n",
    "    The center of mass of Plate2 is placed in a rack where the coordinate is {x: 0.92, y: 0.39, z: 0.82}m.\n",
    "    The center of mass of Plate3 is placed in a rack where the coordinate is {x: 0.86, y: 0.39, z: 0.82}m.\n",
    "    The center of mass of Plate4 is placed in a rack where the coordinate is {x: 0.81, y: 0.39, z: 0.82}m.\n",
    "    The rack has slots aligned along the y-axis.\n",
    "\n",
    "    Place a dish plate into a dish rack, and tell me the range.\n",
    "\n",
    "    [start of plan]\n",
    "    [optional] To perform this task, the manipulator's gripper should move close to dish plate\n",
    "    [optional] dish plate should be close to dish rack.\n",
    "    [optional] The center of mass of dish rack is placed on {x:0.9, y:0.35, z:0.82}m.\n",
    "    [optional] The range of the dish plate is able to be placed in the dish rack {MINIMUM RANGE: 0.0, 0.0, 0.0}m and {MAXIMUM RANGE: 0.0, 0.0, 0.0}.\n",
    "    [end of plan]\n",
    "\n",
    "    Rules:\n",
    "    1. If you see phrases like {MINIMUM RANGE: default x value, default y value, default z value}, {MAXIMUM RANGE: default x value, default y value, default z value}\n",
    "    replace the entire phrase with a numerical value.\n",
    "    2. If you see [optional], it means you only add that line if necessary for the task, otherwise remove that line.\n",
    "    3. Do not invent new objects not listed here.\n",
    "    4. I will tell you a behavior/skill/task that I want the manipulator to perform and you will provide the full plan,\n",
    "    even if you may only need to change a few lines. Always start the description with [start of plan] and end it with [end of plan].\n",
    "    5. You can assume that the robot is capable of doing anything, even for the most challenging task.\n",
    "    6. Your plan should be as close to the provided template as possible. Do not include additional details.\n",
    "    7. The robot is facing towards positive x-axis, positive y-axis is to the left of the robot, positive z-axis is upward.\n",
    "    8. Objects are free to move around unless a command is given.\n",
    "    9. Answer the range {MINIMUM RANGE: 0.0, 0.0, 0.0}m and {MAXIMUM RANGE: 0.0, 0.0, 0.0} where a dish is able to be placed in the dish rack.\n",
    "    If you understand, say Yes.\n",
    "    '''\n",
    "\n",
    "    response = llm.get_answer(prompt)\n",
    "    print(\"Answer: \", response)\n",
    "\n",
    "\n",
    "    # llm = ChatGPT(model_engine=engine)\n",
    "    prompt = '''\n",
    "    We have a plan of a robot arm with gripper to place objects and we want you to turn that into the corresponding reward specifying program with following functions:\n",
    "\n",
    "    ```\n",
    "    def set_l2_distance_reward(name_obj_A, name_obj_B)\n",
    "    ```\n",
    "    where name_obj_A and name_obj_B are selected from ['dish rack', 'dish plate'].\n",
    "    This term sets a reward for minimizing l2_distance between name_obj_A and name_obj_B so they get closer to each other.\n",
    "\n",
    "    ```\n",
    "    def set_obj_orientation_reward(name_obj, x_axis_rotation_radians, z_axis_rotation_radians)\n",
    "    ```\n",
    "    this term encourages the orientation of name_obj to be close to the target.\n",
    "\n",
    "    ```\n",
    "    def execute_plan(duration=2)\n",
    "    ```\n",
    "    This function sends the parameters to the robot and execute the plan for `duration` seconds, default to be 2\n",
    "\n",
    "    ```\n",
    "    def set_obj_position_reward(name_obj, x_offset, y_offset, z_height)\n",
    "    ```\n",
    "    this term encourages the position of name_obj to be close to the specified target position.\n",
    "\n",
    "    ```\n",
    "    def reset_reward()\n",
    "    ```\n",
    "    This function resets the reward to default values.\n",
    "\n",
    "    This is the first plan for a new task.\n",
    "\n",
    "    Example answer code:\n",
    "    ```\n",
    "    import numpy as np\n",
    "\n",
    "    reset_reward() # This is a new task so reset reward; otherwise we don't need it\n",
    "    set_l2_distance_reward(\"dish rack\", \"dish plate\")\n",
    "    set_obj_orientation_reward(\"dish plate\", np.deg2rad(30), 0)\n",
    "    set_obj_position_reward(\"dish plate\", 0, 0, 1.0)\n",
    "\n",
    "    execute_plan(4)\n",
    "    ```\n",
    "\n",
    "    Remember:\n",
    "    1. Always format the code in code blocks. In your response execute_plan should be called exactly once at the end.\n",
    "    2. Do not invent new functions or classes. The only allowed functions you can call are the ones listed above. Do not leave unimplemented code blocks in your response.\n",
    "    3. The only allowed library is numpy. Do not import or use any other library.\n",
    "    4. If you are not sure what value to use, just use your best judge. Do not use None for anything.\n",
    "    5. Do not calculate the position or direction of any object (except for the ones provided above). Just use a number directly based on your best guess.\n",
    "    6. You do not need to make the robot do extra things not mentioned in the plan such as stopping the robot.\n",
    "\n",
    "    If you understand, say Yes.\n",
    "    '''\n",
    "    response = llm.get_answer(prompt)\n",
    "    print(\"Answer: \", response)\n",
    "\n",
    "\n",
    "    prompt = \"Put a dish plate into a dish rack\"\n",
    "    \n",
    "    response = llm.get_answer(prompt)\n",
    "    print(\"Answer: \", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = np.array([0.9,0.35,0.82])\n",
    "# Init viewer\n",
    "env.init_viewer(viewer_title='UR5e with RG2 gripper',viewer_width=1200,viewer_height=800,\n",
    "                viewer_hide_menus=True, MODE='window')\n",
    "env.update_viewer(azimuth=30,distance=3.0,elevation=-30,lookat=[1.0,0.0,0.71],\n",
    "                VIS_TRANSPARENT=False,VIS_CONTACTPOINT=False,\n",
    "                contactwidth=0.05,contactheight=0.05,contactrgba=np.array([1,0,0,1]),\n",
    "                VIS_JOINT=False,jointlength=0.25,jointwidth=0.05,jointrgba=[0.2,0.6,0.8,0.6])\n",
    "\n",
    "pcd_tick = 0\n",
    "\n",
    "# Reset\n",
    "env.reset()\n",
    "init_ur_q = np.array([np.deg2rad(-90), np.deg2rad(-130), np.deg2rad(120), np.deg2rad(100), np.deg2rad(45), np.deg2rad(-90)])\n",
    "env.forward(q=init_ur_q, joint_idxs=env.idxs_forward)\n",
    "initial_xyz = env.get_p_body('tcp_link')\n",
    "print(env.get_p_body('tcp_link'))\n",
    "tick,max_sec = 0,2\n",
    "\n",
    "\n",
    "# Target dish\n",
    "env.model.joint(env.model.body('kitchen-plate').jntadr[0]).qpos0[:3] = np.array([res[0], res[1], 0.82+0.25])\n",
    "env.model.joint(env.model.body('kitchen-plate').jntadr[0]).qpos0[3:] = r2quat(rpy2r(np.radians([0, 90, 90])))\n",
    "while env.get_sim_time() <= max_sec:\n",
    "    env.step(ctrl=init_ur_q,ctrl_idxs=env.idxs_step)\n",
    "    if not env.is_viewer_alive(): break\n",
    "    # Render\n",
    "    if env.loop_every(HZ=20):\n",
    "        # Compute some poses\n",
    "        p_tcp,R_tcp = env.get_pR_body(body_name='tcp_link')\n",
    "        p_cam,R_cam = env.get_pR_body(body_name='camera_center')\n",
    "        p_base,R_base = env.get_pR_body(body_name='base')\n",
    "        # Get PCD from a specific view\n",
    "        p_ego  = p_cam\n",
    "        p_trgt = p_cam + R_cam[:,2] + np.array([0,0,-0.1])\n",
    "        rgb_img,depth_img,pcd,xyz_img = env.get_egocentric_rgb_depth_pcd(\n",
    "            p_ego=p_ego,p_trgt=p_trgt,rsz_rate=40,fovy=45,BACKUP_AND_RESTORE_VIEW=True)\n",
    "        env.render(render_every=1)\n",
    "plt.imshow(rgb_img); plt.axis('off'); plt.show()\n",
    "plt.imshow(depth_img); plt.axis('off'); plt.show()\n",
    "p_dish2, R_dish2 = env.get_pR_body(body_name='kitchen-plate-2')\n",
    "\n",
    "# Close viewer\n",
    "env.close_viewer()\n",
    "print (\"Done. Tick:[%d] Time:[%.2f]sec\"%(env.tick,env.get_sim_time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
